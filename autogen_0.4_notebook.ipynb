{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Multi-Agent Using AutoGen 0.4\n",
    "\n",
    "- AutoGen v0.4\n",
    "\n",
    "    - Observability, Flexibility, Interactive Control, Scale ë“±ì˜ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ë¹„ë™ê¸° ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¡œ ìƒˆë¡­ê²Œ ì„¤ê³„ \n",
    "\n",
    "    - Core API: ì—ì´ì „íŠ¸ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°ë¥¼ ë§Œë“¤ ìˆ˜ ìˆëŠ” í™•ì¥ ê°€ëŠ¥í•œ ì´ë²¤íŠ¸ ê¸°ë°˜ Actor í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µ\n",
    "\n",
    "    - AgentChat API: ì¸í„°ë™í‹°ë¸Œ ì—ì´ì „íŠ¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•´ Core API ìœ„ì— êµ¬ì¶•ëœ íƒœìŠ¤í¬ ê¸°ë°˜ ê³ ìˆ˜ì¤€ í”„ë ˆì„ì›Œí¬ (v0.2 ëŒ€ì²´)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.13/site-packages (25.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: chroma in ./.venv/lib/python3.13/site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.13/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: markdownify in ./.venv/lib/python3.13/site-packages (0.14.1)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.9 in ./.venv/lib/python3.13/site-packages (from markdownify) (4.13.3)\n",
      "Requirement already satisfied: six<2,>=1.15 in ./.venv/lib/python3.13/site-packages (from markdownify) (1.17.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.13/site-packages (from beautifulsoup4<5,>=4.9->markdownify) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.13/site-packages (from beautifulsoup4<5,>=4.9->markdownify) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: apify_client in ./.venv/lib/python3.13/site-packages (1.9.2)\n",
      "Requirement already satisfied: apify-shared>=1.1.2 in ./.venv/lib/python3.13/site-packages (from apify_client) (1.2.1)\n",
      "Requirement already satisfied: httpx>=0.25 in ./.venv/lib/python3.13/site-packages (from apify_client) (0.28.1)\n",
      "Requirement already satisfied: more_itertools>=10.0.0 in ./.venv/lib/python3.13/site-packages (from apify_client) (10.6.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx>=0.25->apify_client) (4.8.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx>=0.25->apify_client) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx>=0.25->apify_client) (1.0.7)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx>=0.25->apify_client) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.25->apify_client) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.13/site-packages (from anyio->httpx>=0.25->apify_client) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: duckduckgo-search in ./.venv/lib/python3.13/site-packages (7.3.2)\n",
      "Requirement already satisfied: click>=8.1.8 in ./.venv/lib/python3.13/site-packages (from duckduckgo-search) (8.1.8)\n",
      "Requirement already satisfied: primp>=0.11.0 in ./.venv/lib/python3.13/site-packages (from duckduckgo-search) (0.12.1)\n",
      "Requirement already satisfied: lxml>=5.3.0 in ./.venv/lib/python3.13/site-packages (from duckduckgo-search) (5.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: autogen_core in ./.venv/lib/python3.13/site-packages (0.4.7)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in ./.venv/lib/python3.13/site-packages (from autogen_core) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.27.0 in ./.venv/lib/python3.13/site-packages (from autogen_core) (1.30.0)\n",
      "Requirement already satisfied: pillow>=11.0.0 in ./.venv/lib/python3.13/site-packages (from autogen_core) (11.1.0)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in ./.venv/lib/python3.13/site-packages (from autogen_core) (5.29.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in ./.venv/lib/python3.13/site-packages (from autogen_core) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.13/site-packages (from autogen_core) (4.12.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./.venv/lib/python3.13/site-packages (from opentelemetry-api>=1.27.0->autogen_core) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-api>=1.27.0->autogen_core) (8.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.10.0->autogen_core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.10.0->autogen_core) (2.27.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.13/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->autogen_core) (1.17.2)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.13/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.27.0->autogen_core) (3.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: autogen_ext in ./.venv/lib/python3.13/site-packages (0.4.7)\n",
      "Requirement already satisfied: autogen-core==0.4.7 in ./.venv/lib/python3.13/site-packages (from autogen_ext) (0.4.7)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in ./.venv/lib/python3.13/site-packages (from autogen-core==0.4.7->autogen_ext) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.27.0 in ./.venv/lib/python3.13/site-packages (from autogen-core==0.4.7->autogen_ext) (1.30.0)\n",
      "Requirement already satisfied: pillow>=11.0.0 in ./.venv/lib/python3.13/site-packages (from autogen-core==0.4.7->autogen_ext) (11.1.0)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in ./.venv/lib/python3.13/site-packages (from autogen-core==0.4.7->autogen_ext) (5.29.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in ./.venv/lib/python3.13/site-packages (from autogen-core==0.4.7->autogen_ext) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.13/site-packages (from autogen-core==0.4.7->autogen_ext) (4.12.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./.venv/lib/python3.13/site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.4.7->autogen_ext) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.4.7->autogen_ext) (8.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.4.7->autogen_ext) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.4.7->autogen_ext) (2.27.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.13/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->autogen-core==0.4.7->autogen_ext) (1.17.2)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.13/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.4.7->autogen_ext) (3.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: autogen_agentchat in ./.venv/lib/python3.13/site-packages (0.4.7)\n",
      "Requirement already satisfied: autogen-core==0.4.7 in ./.venv/lib/python3.13/site-packages (from autogen_agentchat) (0.4.7)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in ./.venv/lib/python3.13/site-packages (from autogen-core==0.4.7->autogen_agentchat) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.27.0 in ./.venv/lib/python3.13/site-packages (from autogen-core==0.4.7->autogen_agentchat) (1.30.0)\n",
      "Requirement already satisfied: pillow>=11.0.0 in ./.venv/lib/python3.13/site-packages (from autogen-core==0.4.7->autogen_agentchat) (11.1.0)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in ./.venv/lib/python3.13/site-packages (from autogen-core==0.4.7->autogen_agentchat) (5.29.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in ./.venv/lib/python3.13/site-packages (from autogen-core==0.4.7->autogen_agentchat) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.13/site-packages (from autogen-core==0.4.7->autogen_agentchat) (4.12.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./.venv/lib/python3.13/site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.4.7->autogen_agentchat) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.4.7->autogen_agentchat) (8.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.4.7->autogen_agentchat) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.4.7->autogen_agentchat) (2.27.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.13/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->autogen-core==0.4.7->autogen_agentchat) (1.17.2)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.13/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.4.7->autogen_agentchat) (3.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: azure-core in ./.venv/lib/python3.13/site-packages (1.32.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in ./.venv/lib/python3.13/site-packages (from azure-core) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in ./.venv/lib/python3.13/site-packages (from azure-core) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in ./.venv/lib/python3.13/site-packages (from azure-core) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.21.0->azure-core) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests>=2.21.0->azure-core) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.21.0->azure-core) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests>=2.21.0->azure-core) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: azure-identity in ./.venv/lib/python3.13/site-packages (1.20.0)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in ./.venv/lib/python3.13/site-packages (from azure-identity) (1.32.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in ./.venv/lib/python3.13/site-packages (from azure-identity) (44.0.1)\n",
      "Requirement already satisfied: msal>=1.30.0 in ./.venv/lib/python3.13/site-packages (from azure-identity) (1.31.1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in ./.venv/lib/python3.13/site-packages (from azure-identity) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.13/site-packages (from azure-identity) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in ./.venv/lib/python3.13/site-packages (from azure-core>=1.31.0->azure-identity) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in ./.venv/lib/python3.13/site-packages (from azure-core>=1.31.0->azure-identity) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.12 in ./.venv/lib/python3.13/site-packages (from cryptography>=2.5->azure-identity) (1.17.1)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in ./.venv/lib/python3.13/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity) (2.10.1)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in ./.venv/lib/python3.13/site-packages (from msal-extensions>=1.2.0->azure-identity) (2.10.1)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.13/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "%pip install --upgrade pip\n",
    "\n",
    "%pip install chroma             # Chroma DB\n",
    "%pip install python-dotenv\n",
    "%pip install markdownify\n",
    "%pip install apify_client\n",
    "%pip install duckduckgo-search  # DuckDuckGo Search\n",
    "%pip install autogen_core\n",
    "%pip install autogen_ext\n",
    "%pip install autogen_agentchat\n",
    "%pip install azure-core\n",
    "%pip install azure-identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì´ˆê¸°í™” "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .env íŒŒì¼ í¸ì§‘ \n",
    " - ì•„ë˜ 3ê°€ì§€ API í‚¤ë¥¼ .env íŒŒì¼ì— ì—…ë°ì´íŠ¸ í•©ë‹ˆë‹¤.\n",
    "    - OPENAI_API_KEY=<YOUR_API_KEY>\n",
    "    - BING_API_KEY=<YOUR_BING_API_KEY>\n",
    "    - APIFY_API_KEY=<YOUR_APIFY_API_KEY>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in ./.venv/lib/python3.13/site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.13/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.13/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.13/site-packages (1.63.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.13/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.13/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.13/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from autogen_core.models import ChatCompletionClient\n",
    "\n",
    "config = {\n",
    "    \"provider\": \"AzureOpenAIChatCompletionClient\",\n",
    "    \"config\": {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"api_key\": os.environ[\"OPENAI_API_KEY\"], \n",
    "        \"api_version\": \"2024-02-01\",\n",
    "        \"azure_deployment\": \"gpt-4o\",\n",
    "        \"azure_endpoint\": os.environ[\"OPENAI_URL\"],\n",
    "    }\n",
    "}\n",
    "\n",
    "model_client = ChatCompletionClient.load_component(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-agent chat: \n",
    " - ê°€ì¥ ê°„ë‹¨í•œ ëŒ€í™” íŒ¨í„´ìœ¼ë¡œ, ë‘ ì—ì´ì „íŠ¸ê°€ Autogenì„ ì‚¬ìš©í•˜ì—¬ ì„œë¡œ ëŒ€í™”\n",
    " - summary_method: ì±„íŒ…ì—ì„œ ìš”ì•½ì„ ì–»ê¸° ìœ„í•œ ë°©ë²•ìœ¼ë¡œ ì±„íŒ… ê¸°ë¡ì—ì„œ ë§ˆì§€ë§‰ ë©”ì‹œì§€ë¥¼ ìš”ì•½ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” last_msgì™€, ì±„íŒ… ê¸°ë¡ì„ ë°˜ì˜í•˜ì—¬ LLM í˜¸ì¶œì„ ì‚¬ìš©í•´ ìš”ì•½ì„ ì œê³µí•˜ëŠ” reflection_with_llm ë“±ì´ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/autogen_image1.png\" alt=\"GroupChat Flow\" width=\"500\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "ì¸ê³µì§€ëŠ¥ì´ ì‹¤ì œë¡œ ì§€ëŠ¥ì ì„ì„ ì–´ë–»ê²Œ ì¦ëª…í•˜ê±°ë‚˜ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆì„ê¹Œìš”?\n",
      "---------- Teacher_Agent ----------\n",
      "ì¸ê³µì§€ëŠ¥ì´ \"ì§€ëŠ¥ì \"ì„ì„ ì¦ëª…í•˜ê±°ë‚˜ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê²ƒì€ ë³µì¡í•œ ë¬¸ì œë¡œ, ë‹¤ì–‘í•œ ë°©ë²•ê³¼ ì ‘ê·¼ë²•ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ í…ŒìŠ¤íŠ¸ì™€ í‰ê°€ ë°©ë²•ì€ ì¢…ì¢… ì¸ê³µì§€ëŠ¥ì´ íŠ¹ì • ì‘ì—…ì„ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰í•˜ëŠ”ì§€ë¥¼ ì¸¡ì •í•˜ê±°ë‚˜ ì¸ê°„ê³¼ì˜ ë¹„êµë¥¼ í†µí•´ ì§„í–‰ë©ë‹ˆë‹¤. ëª‡ ê°€ì§€ ì£¼ìš” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. **íŠœë§ í…ŒìŠ¤íŠ¸ (Turing Test)**: ì•¨ëŸ° íŠœë§ì´ ì œì•ˆí•œ ì´ í…ŒìŠ¤íŠ¸ëŠ” ê¸°ê³„ê°€ ì¸ê°„ê³¼ êµ¬ë¶„ë˜ì§€ ì•Šì„ ì •ë„ë¡œ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ëŠ” ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë§Œì•½ í‰ê°€ìê°€ ê¸°ê³„ì™€ ì¸ê°„ì„ êµ¬ë¶„í•  ìˆ˜ ì—†ë‹¤ë©´, ê·¸ ê¸°ê³„ëŠ” 'ì§€ëŠ¥ì 'ì´ë¼ê³  íŒë‹¨í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **CAPTCHA í…ŒìŠ¤íŠ¸**: ì‚¬ëŒê³¼ ê¸°ê³„ë¥¼ êµ¬ë³„í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ, ëŒ€ë¶€ë¶„ì˜ AIëŠ” ì¸ê°„ì²˜ëŸ¼ ìˆ˜ì›”í•˜ê²Œ í†µê³¼í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì´ ì—­ì‹œ ì¸ê³µì§€ëŠ¥ì˜ í•œê³„ì™€ ëŠ¥ë ¥ì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ëŠ¥ë ¥ ê¸°ë°˜ í‰ê°€**: íŠ¹ì • ë¬¸ì œ í•´ê²° ëŠ¥ë ¥, íŒ¨í„´ ì¸ì‹, ìì—°ì–´ ì²˜ë¦¬ ë“±ì˜ ëŠ¥ë ¥ì„ ê°œë³„ì ìœ¼ë¡œ ì¸¡ì •í•˜ì—¬ í‰ê°€í•©ë‹ˆë‹¤. ì´ëŸ° í…ŒìŠ¤íŠ¸ëŠ” ì§€ëŠ¥ì˜ ì—¬ëŸ¬ ì¸¡ë©´ì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **ë²¤ì¹˜ë§ˆí¬ì™€ ëŒ€íšŒ**: ê°ì¢… ì¸ê³µì§€ëŠ¥ ê´€ë ¨ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ë‚˜ ëŒ€íšŒë¥¼ í†µí•´ ì„±ëŠ¥ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì´ë¯¸ì§€ ì¸ì‹ ëŒ€íšŒ(ì˜ˆ: ImageNet), ìì—°ì–´ ì²˜ë¦¬ ëŒ€íšŒ(ì˜ˆ: GLUE) ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "5. **ì œë„ˆëŸ´ ì¸í…”ë¦¬ì „ìŠ¤ í…ŒìŠ¤íŠ¸**: ì¸ê°„ ì§€ëŠ¥ì˜ ì—¬ëŸ¬ íŠ¹ì§•ì„ ëª¨ë°©í•˜ëŠ” ë²”ìš© ì¸ê³µì§€ëŠ¥(AGI)ì„ ì—¼ë‘ì— ë‘ê³  ì„¤ê³„ëœ í…ŒìŠ¤íŠ¸ë¡œ, ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œì˜ ìœ ì—°ì„±ê³¼ ì ì‘ë ¥ì„ í‰ê°€í•˜ë ¤ëŠ” ì‹œë„ì…ë‹ˆë‹¤.\n",
      "\n",
      "6. **ì¸ê°„-ì»´í“¨í„° ìƒí˜¸ì‘ìš© í‰ê°€**: ì¸ê³µì§€ëŠ¥ì´ ì¸ê°„ê³¼ ì–¼ë§ˆë‚˜ ìì—°ìŠ¤ëŸ½ê³  ìœ ìµí•˜ê²Œ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. ì´ëŠ” ì‚¬ìš©ì ê²½í—˜ì„ í†µí•´ ì§ê´€ì ìœ¼ë¡œ AIì˜ ì§€ëŠ¥ì„ ëŠë‚„ ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ë°©ë²•ë“¤ì€ ê°ê°ì˜ í•œê³„ì™€ ì¥ì ì´ ìˆìœ¼ë©°, ì¸ê³µì§€ëŠ¥ì˜ ì§€ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ì„ ë³‘í–‰í•´ì„œ ë³´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë˜í•œ, 'ì§€ëŠ¥'ì´ë¼ëŠ” ê°œë… ìì²´ê°€ ë‹¤ì–‘í•˜ê³  ë³µí•©ì ì´ê¸° ë•Œë¬¸ì—, AIì˜ ì§€ëŠ¥ì„ ëª…í™•í•˜ê²Œ ì •ì˜í•˜ê³  í‰ê°€í•˜ëŠ” ê²ƒì€ ì—¬ì „íˆ ì—°êµ¬ ì¤‘ì¸ ë¶„ì•¼ì…ë‹ˆë‹¤.\n",
      "---------- Teacher_Agent ----------\n",
      "í˜¹ì€ ìš°ë¦¬ëŠ” AI ì‹œìŠ¤í…œì˜ ì§€ëŠ¥ì„ íŠ¹ì •í•œ ì—…ë¬´ ìˆ˜í–‰ ëŠ¥ë ¥ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´:\n",
      "\n",
      "7. **êµ¬ì²´ì ì¸ ì‘ì—… ì„±ì·¨ë„**: AIê°€ íŠ¹ì • ì‘ì—…ì„ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì‹œìŠ¤í…œì˜ ìœ ìš©ì„±ì´ë‚˜ ì‹¤ì§ˆì ì¸ ì§€ëŠ¥ì„ ì¸¡ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆì‹œëŠ” ì²´ìŠ¤ë‚˜ ë°”ë‘‘ ê°™ì€ ê²Œì„ì—ì„œ ì¸ê°„ ì±”í”¼ì–¸ê³¼ì˜ ëŒ€ê²° ì„±ê³¼ì…ë‹ˆë‹¤.\n",
      "\n",
      "8. **í•™ìŠµ ì†ë„ì™€ ì ì‘ë ¥**: ì£¼ì–´ì§„ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê³  ìƒí™©ì— ì ì‘í•˜ëŠ” ëŠ¥ë ¥ ì—­ì‹œ AIì˜ ì§€ëŠ¥ì„ í‰ê°€í•  ìˆ˜ ìˆëŠ” ìš”ì†Œì…ë‹ˆë‹¤. ì¦‰, ë³€í™”í•˜ëŠ” í™˜ê²½ì—ì„œ ì–¼ë§ˆë‚˜ ë¹ ë¥´ê²Œ ì ì‘í•˜ê³  ìƒˆë¡œìš´ íŒ¨í„´ì„ ì´í•´í•˜ëŠ”ì§€ê°€ í•˜ë‚˜ì˜ ì²™ë„ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "9. **ë¬¸ë§¥ ì´í•´ì™€ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥**: íŠ¹íˆ ìì—°ì–´ ì²˜ë¦¬(NLP) ë¶„ì•¼ì—ì„œ ë¬¸ë§¥ì„ ì´í•´í•˜ê³  ê·¸ì— ë§ëŠ” ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ëŠ¥ë ¥ì„ í‰ê°€í•¨ìœ¼ë¡œì¨ ì•Œì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” AIê°€ ë‹¨ìˆœí•œ ê·œì¹™ ê¸°ë°˜ì˜ ì‘ë‹µì—ì„œ ë²—ì–´ë‚˜ ì–¼ë§ˆë‚˜ ì¸ê°„ë‹¤ìš´ ì‚¬ê³ ë¥¼ í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
      "\n",
      "ê°ê°ì˜ ë°©ë²•ì€ íŠ¹ì • ìœ í˜•ì˜ ì§€ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° íš¨ê³¼ì ì¼ ìˆ˜ ìˆìœ¼ë©°, ì¢…ì¢… ì„œë¡œ ë‹¤ë¥¸ ë°©ë²•ì„ ê²°í•©í•˜ì—¬ AI ì‹œìŠ¤í…œì˜ ì§€ëŠ¥ì„ ë³´ë‹¤ í¬ê´„ì ìœ¼ë¡œ ì´í•´í•˜ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤. AIì˜ ì§€ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° ìˆì–´ ì¤‘ìš”í•œ ì ì€ ê·¸ ì‹œìŠ¤í…œì´ ì„¤ê³„ëœ ëª©ì ê³¼ ê·¸ì— ë§ëŠ” ëŠ¥ë ¥ì„ ì–¼ë§ˆë‚˜ ì˜ ë°œíœ˜í•˜ëŠëƒì…ë‹ˆë‹¤. ê¶ê·¹ì ìœ¼ë¡œ 'ì§€ëŠ¥'ì€ ì •ëŸ‰í™”í•˜ê¸° ì‰½ì§€ ì•Šì€ ê°œë…ì´ë¯€ë¡œ, ê·¸ê²ƒì„ ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í•˜ê³  í‰ê°€í•˜ëŠ” ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='ì¸ê³µì§€ëŠ¥ì´ ì‹¤ì œë¡œ ì§€ëŠ¥ì ì„ì„ ì–´ë–»ê²Œ ì¦ëª…í•˜ê±°ë‚˜ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆì„ê¹Œìš”?', type='TextMessage'), TextMessage(source='Teacher_Agent', models_usage=RequestUsage(prompt_tokens=51, completion_tokens=525), content='ì¸ê³µì§€ëŠ¥ì´ \"ì§€ëŠ¥ì \"ì„ì„ ì¦ëª…í•˜ê±°ë‚˜ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê²ƒì€ ë³µì¡í•œ ë¬¸ì œë¡œ, ë‹¤ì–‘í•œ ë°©ë²•ê³¼ ì ‘ê·¼ë²•ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ í…ŒìŠ¤íŠ¸ì™€ í‰ê°€ ë°©ë²•ì€ ì¢…ì¢… ì¸ê³µì§€ëŠ¥ì´ íŠ¹ì • ì‘ì—…ì„ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰í•˜ëŠ”ì§€ë¥¼ ì¸¡ì •í•˜ê±°ë‚˜ ì¸ê°„ê³¼ì˜ ë¹„êµë¥¼ í†µí•´ ì§„í–‰ë©ë‹ˆë‹¤. ëª‡ ê°€ì§€ ì£¼ìš” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n\\n1. **íŠœë§ í…ŒìŠ¤íŠ¸ (Turing Test)**: ì•¨ëŸ° íŠœë§ì´ ì œì•ˆí•œ ì´ í…ŒìŠ¤íŠ¸ëŠ” ê¸°ê³„ê°€ ì¸ê°„ê³¼ êµ¬ë¶„ë˜ì§€ ì•Šì„ ì •ë„ë¡œ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ëŠ” ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë§Œì•½ í‰ê°€ìê°€ ê¸°ê³„ì™€ ì¸ê°„ì„ êµ¬ë¶„í•  ìˆ˜ ì—†ë‹¤ë©´, ê·¸ ê¸°ê³„ëŠ” \\'ì§€ëŠ¥ì \\'ì´ë¼ê³  íŒë‹¨í•©ë‹ˆë‹¤.\\n\\n2. **CAPTCHA í…ŒìŠ¤íŠ¸**: ì‚¬ëŒê³¼ ê¸°ê³„ë¥¼ êµ¬ë³„í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ, ëŒ€ë¶€ë¶„ì˜ AIëŠ” ì¸ê°„ì²˜ëŸ¼ ìˆ˜ì›”í•˜ê²Œ í†µê³¼í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì´ ì—­ì‹œ ì¸ê³µì§€ëŠ¥ì˜ í•œê³„ì™€ ëŠ¥ë ¥ì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n3. **ëŠ¥ë ¥ ê¸°ë°˜ í‰ê°€**: íŠ¹ì • ë¬¸ì œ í•´ê²° ëŠ¥ë ¥, íŒ¨í„´ ì¸ì‹, ìì—°ì–´ ì²˜ë¦¬ ë“±ì˜ ëŠ¥ë ¥ì„ ê°œë³„ì ìœ¼ë¡œ ì¸¡ì •í•˜ì—¬ í‰ê°€í•©ë‹ˆë‹¤. ì´ëŸ° í…ŒìŠ¤íŠ¸ëŠ” ì§€ëŠ¥ì˜ ì—¬ëŸ¬ ì¸¡ë©´ì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n4. **ë²¤ì¹˜ë§ˆí¬ì™€ ëŒ€íšŒ**: ê°ì¢… ì¸ê³µì§€ëŠ¥ ê´€ë ¨ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ë‚˜ ëŒ€íšŒë¥¼ í†µí•´ ì„±ëŠ¥ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì´ë¯¸ì§€ ì¸ì‹ ëŒ€íšŒ(ì˜ˆ: ImageNet), ìì—°ì–´ ì²˜ë¦¬ ëŒ€íšŒ(ì˜ˆ: GLUE) ë“±ì´ ìˆìŠµë‹ˆë‹¤.\\n\\n5. **ì œë„ˆëŸ´ ì¸í…”ë¦¬ì „ìŠ¤ í…ŒìŠ¤íŠ¸**: ì¸ê°„ ì§€ëŠ¥ì˜ ì—¬ëŸ¬ íŠ¹ì§•ì„ ëª¨ë°©í•˜ëŠ” ë²”ìš© ì¸ê³µì§€ëŠ¥(AGI)ì„ ì—¼ë‘ì— ë‘ê³  ì„¤ê³„ëœ í…ŒìŠ¤íŠ¸ë¡œ, ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œì˜ ìœ ì—°ì„±ê³¼ ì ì‘ë ¥ì„ í‰ê°€í•˜ë ¤ëŠ” ì‹œë„ì…ë‹ˆë‹¤.\\n\\n6. **ì¸ê°„-ì»´í“¨í„° ìƒí˜¸ì‘ìš© í‰ê°€**: ì¸ê³µì§€ëŠ¥ì´ ì¸ê°„ê³¼ ì–¼ë§ˆë‚˜ ìì—°ìŠ¤ëŸ½ê³  ìœ ìµí•˜ê²Œ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. ì´ëŠ” ì‚¬ìš©ì ê²½í—˜ì„ í†µí•´ ì§ê´€ì ìœ¼ë¡œ AIì˜ ì§€ëŠ¥ì„ ëŠë‚„ ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\\n\\nì´ëŸ¬í•œ ë°©ë²•ë“¤ì€ ê°ê°ì˜ í•œê³„ì™€ ì¥ì ì´ ìˆìœ¼ë©°, ì¸ê³µì§€ëŠ¥ì˜ ì§€ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ì„ ë³‘í–‰í•´ì„œ ë³´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë˜í•œ, \\'ì§€ëŠ¥\\'ì´ë¼ëŠ” ê°œë… ìì²´ê°€ ë‹¤ì–‘í•˜ê³  ë³µí•©ì ì´ê¸° ë•Œë¬¸ì—, AIì˜ ì§€ëŠ¥ì„ ëª…í™•í•˜ê²Œ ì •ì˜í•˜ê³  í‰ê°€í•˜ëŠ” ê²ƒì€ ì—¬ì „íˆ ì—°êµ¬ ì¤‘ì¸ ë¶„ì•¼ì…ë‹ˆë‹¤.', type='TextMessage'), TextMessage(source='Teacher_Agent', models_usage=RequestUsage(prompt_tokens=584, completion_tokens=356), content=\"í˜¹ì€ ìš°ë¦¬ëŠ” AI ì‹œìŠ¤í…œì˜ ì§€ëŠ¥ì„ íŠ¹ì •í•œ ì—…ë¬´ ìˆ˜í–‰ ëŠ¥ë ¥ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´:\\n\\n7. **êµ¬ì²´ì ì¸ ì‘ì—… ì„±ì·¨ë„**: AIê°€ íŠ¹ì • ì‘ì—…ì„ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì‹œìŠ¤í…œì˜ ìœ ìš©ì„±ì´ë‚˜ ì‹¤ì§ˆì ì¸ ì§€ëŠ¥ì„ ì¸¡ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆì‹œëŠ” ì²´ìŠ¤ë‚˜ ë°”ë‘‘ ê°™ì€ ê²Œì„ì—ì„œ ì¸ê°„ ì±”í”¼ì–¸ê³¼ì˜ ëŒ€ê²° ì„±ê³¼ì…ë‹ˆë‹¤.\\n\\n8. **í•™ìŠµ ì†ë„ì™€ ì ì‘ë ¥**: ì£¼ì–´ì§„ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê³  ìƒí™©ì— ì ì‘í•˜ëŠ” ëŠ¥ë ¥ ì—­ì‹œ AIì˜ ì§€ëŠ¥ì„ í‰ê°€í•  ìˆ˜ ìˆëŠ” ìš”ì†Œì…ë‹ˆë‹¤. ì¦‰, ë³€í™”í•˜ëŠ” í™˜ê²½ì—ì„œ ì–¼ë§ˆë‚˜ ë¹ ë¥´ê²Œ ì ì‘í•˜ê³  ìƒˆë¡œìš´ íŒ¨í„´ì„ ì´í•´í•˜ëŠ”ì§€ê°€ í•˜ë‚˜ì˜ ì²™ë„ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n9. **ë¬¸ë§¥ ì´í•´ì™€ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥**: íŠ¹íˆ ìì—°ì–´ ì²˜ë¦¬(NLP) ë¶„ì•¼ì—ì„œ ë¬¸ë§¥ì„ ì´í•´í•˜ê³  ê·¸ì— ë§ëŠ” ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ëŠ¥ë ¥ì„ í‰ê°€í•¨ìœ¼ë¡œì¨ ì•Œì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” AIê°€ ë‹¨ìˆœí•œ ê·œì¹™ ê¸°ë°˜ì˜ ì‘ë‹µì—ì„œ ë²—ì–´ë‚˜ ì–¼ë§ˆë‚˜ ì¸ê°„ë‹¤ìš´ ì‚¬ê³ ë¥¼ í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\\n\\nê°ê°ì˜ ë°©ë²•ì€ íŠ¹ì • ìœ í˜•ì˜ ì§€ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° íš¨ê³¼ì ì¼ ìˆ˜ ìˆìœ¼ë©°, ì¢…ì¢… ì„œë¡œ ë‹¤ë¥¸ ë°©ë²•ì„ ê²°í•©í•˜ì—¬ AI ì‹œìŠ¤í…œì˜ ì§€ëŠ¥ì„ ë³´ë‹¤ í¬ê´„ì ìœ¼ë¡œ ì´í•´í•˜ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤. AIì˜ ì§€ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° ìˆì–´ ì¤‘ìš”í•œ ì ì€ ê·¸ ì‹œìŠ¤í…œì´ ì„¤ê³„ëœ ëª©ì ê³¼ ê·¸ì— ë§ëŠ” ëŠ¥ë ¥ì„ ì–¼ë§ˆë‚˜ ì˜ ë°œíœ˜í•˜ëŠëƒì…ë‹ˆë‹¤. ê¶ê·¹ì ìœ¼ë¡œ 'ì§€ëŠ¥'ì€ ì •ëŸ‰í™”í•˜ê¸° ì‰½ì§€ ì•Šì€ ê°œë…ì´ë¯€ë¡œ, ê·¸ê²ƒì„ ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í•˜ê³  í‰ê°€í•˜ëŠ” ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤.\", type='TextMessage')], stop_reason='Maximum number of messages 3 reached, current message count: 3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to web_surfer):\n",
      "\n",
      "ìµœì‹  ì—ì´ì „íŠ¸ ê¸°ìˆ \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION informational_web_search...\n",
      "Call ID: call_EmWZJpxj2eJbAla9F18KmfiM\n",
      "Input arguments: {'query': 'ìµœì‹  ì—ì´ì „íŠ¸ ê¸°ìˆ  2025'}\u001b[0m\n",
      "\u001b[33mweb_surfer\u001b[0m (to user_proxy):\n",
      "\n",
      "Address: bing: ìµœì‹  ì—ì´ì „íŠ¸ ê¸°ìˆ  2025\n",
      "Title: ìµœì‹  ì—ì´ì „íŠ¸ ê¸°ìˆ  2025 - Search\n",
      "Viewport position: Showing page 1 of 1.\n",
      "=======================\n",
      "A Bing search for 'ìµœì‹  ì—ì´ì „íŠ¸ ê¸°ìˆ  2025' found 15 results:\n",
      "\n",
      "## Web Results\n",
      "1. [ê°€íŠ¸ë„ˆ, 2025ë…„ 10ëŒ€ ê¸°ìˆ  íŠ¸ë Œë“œ ì¤‘ 9ê°œê°€ AI...ì—ì´ì „íŠ¸Â·ê³µê°„ì§€ëŠ¥ ...](https://www.aitimes.com/news/articleView.html?idxno=164495)\n",
      "ê¸€ë¡œë²Œ ì‹œì¥ì¡°ì‚¬ ê¸°ê´€ ê°€íŠ¸ë„ˆê°€ 2025ë…„ ì£¼ìš” ê¸°ìˆ  íŠ¸ë Œë“œë¡œ ì¸ê³µì§€ëŠ¥ (AI) ì—ì´ì „íŠ¸ë¥¼ ê°€ì¥ ë¨¼ì € ê¼½ì•˜ë‹¤. ì—¬ê¸°ì— ìµœê·¼ ë– ì˜¤ë¥´ëŠ” 'ê³µê°„ ì§€ëŠ¥' ë“± AI ê´€ë ¨ ê¸°ìˆ ì´ ë¬´ë ¤ 9ê°œ í•­ëª©ì„ ì°¨ì§€í–ˆë‹¤. ê°€íŠ¸ë„ˆëŠ” 21ì¼ (í˜„ì§€ì‹œê°„) '2025ë…„ 10ëŒ€ ì „ëµ ê¸°ìˆ  íŠ¸ë Œë“œ'ë¼ëŠ” ë³´ê³ ì„œë¥¼ í†µí•´ 10ê°€ì§€ ì£¼ìš” ê¸°ìˆ ì„ ì†Œê°œí–ˆë‹¤. ì´ì¤‘ AIë¥¼ ì§ì ‘ ê±°ë¡ í•œ ê¸°ìˆ ë¡œëŠ” ì—ì´ì „íŠ¸ AI (Agentic AI) AI ê±°ë²„ë„ŒìŠ¤ í”Œë«í¼ (AI Governance Platforms) í—ˆìœ„ì •ë³´ ë³´ì•ˆ (Disinformation Security) ê³µê°„ ì§€ëŠ¥ (Spatial Computing) ë“±ì´ ëŒ€í‘œì ì´ë‹¤.\n",
      "\n",
      "2. [2025ë…„ ì£¼ëª©í•´ì•¼ í•  ì¸ê³µì§€ëŠ¥(AI) ê¸°ìˆ  TOP 6](https://pc-money.tistory.com/entry/2025%EB%85%84-%EC%A3%BC%EB%AA%A9%ED%95%B4%EC%95%BC-%ED%95%A0-%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5AI-%EA%B8%B0%EC%88%A0-TOP-6)\n",
      "ğŸ“Œ 3. ììœ¨ ì—ì´ì „íŠ¸(AI Agent) ğŸ”¹ AIê°€ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ê³  í–‰ë™í•˜ëŠ” ì‹œëŒ€! 2025ë…„ì—ëŠ” ììœ¨ ì—ì´ì „íŠ¸(AI Agent) ê¸°ìˆ ì´ ë”ìš± ë°œì „í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤. ê¸°ì¡´ì˜ AIëŠ” ì‚¬ìš©ìì˜ ëª…ë ¹ì„ ìˆ˜í–‰í•˜ëŠ” ë° ì´ˆì ì´ ë§ì¶°ì ¸ ìˆì—ˆì§€ë§Œ, ì´ì œëŠ” ìŠ¤ìŠ¤ë¡œ ëª©í‘œë¥¼ ì„¤ì •í•˜ê³ , ë¬¸ì œë¥¼ í•´ê²°í•˜ë©°, í•™ìŠµê¹Œì§€ ì§„í–‰í•˜ëŠ” AIê°€ ë“±ì¥í•˜ê³  ...\n",
      "\n",
      "3. [Char :: 2025 - ê°€íŠ¸ë„ˆ, 2025ë…„ 10ëŒ€ ì „ëµ ê¸°ìˆ  íŠ¸ë Œë“œ](https://charstring.tistory.com/1459)\n",
      "ë¯¸êµ­ì˜ IT ìë¬¸ íšŒì‚¬ ê°€íŠ¸ë„ˆ (Gartner)ê°€ 2025ë…„ì„ ìœ„í•œ ì£¼ìš” ì „ëµ ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. ì´ ë¦¬í¬íŠ¸ëŠ” CIOì™€ IT ë¦¬ë”ë“¤ì´ ë¯¸ë˜ ì „ëµì„ ì„¸ìš°ëŠ” ë° í•„ìš”í•œ ë°©í–¥ì„ ì œì‹œí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆëŠ”ë°ìš”. 'AI ì—ì´ì „íŠ¸ (Agentic AI)'ë¥¼ ì‹œì‘ìœ¼ë¡œ 10ëŒ€ ê¸°ìˆ  ì¤‘ 9ê°œê°€ AIì™€ ê´€ë ¨ëœ ê¸°ìˆ ë¡œ êµ¬ì„±ë¼ ìˆì–´, AIì˜ ì¤‘ìš”ì„±ì´ ë‹¤ì‹œ í•œë²ˆ ê°•ì¡°ëìŠµë‹ˆë‹¤. ê°€íŠ¸ë„ˆëŠ” ì´ë²ˆ ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ ì„¸ ê°€ì§€ í…Œë§ˆë¡œ ë‚˜ëˆ„ì–´ ì„¤ëª…í–ˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ í…Œë§ˆëŠ” ì¡°ì§ì˜ ë³´í˜¸ì™€ AIì— ê´€ë ¨ëœ ê¸°ìˆ ì¸ë°ìš”. AI ì—ì´ì „íŠ¸ëŠ” ììœ¨ì ìœ¼ë¡œ ëª©í‘œë¥¼ ì„¤ì •í•˜ê³  ì‹¤í–‰í•˜ë©°, ê±°ë²„ë„ŒìŠ¤ í”Œë«í¼ì€ ìœ¤ë¦¬ì ì´ê³  ë²•ì ì¸ ì±…ì„ ê°•í™”ë¥¼ ë•ìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. [[ì „ìì‹ ë¬¸ì¸í„°ë„· ì»¨í¼ëŸ°ìŠ¤] AI Agent Shift 2025](https://conference.etnews.com/conf_info.html?uid=362)\n",
      "â€˜AI Agent Shift 2025â€™ëŠ” ì´ëŸ¬í•œ ì‹œëŒ€ì  íë¦„ì„ ì£¼ë„í•˜ëŠ” ê¸°ìˆ ê³¼ ì‹¤ì œ ì‘ìš© ì‚¬ë¡€ë¥¼ ê³µìœ í•˜ë©°, AI ì—ì´ì „íŠ¸ì˜ ë¯¸ë˜ë¥¼ ì „ë§í•˜ëŠ” ìë¦¬ì…ë‹ˆë‹¤. ê¹Šì€ ì¸ì‚¬ì´íŠ¸ë¥¼ ì£¼ëŠ” í‚¤ë…¸íŠ¸ ìŠ¤í”¼ì¹˜ì™€ ìµœì‹  ê¸°ìˆ  ë™í–¥ì„ ì‚´í´ë³¼ ìˆ˜ ìˆëŠ” ê¸°ìˆ  ì„¸ì…˜ ê·¸ë¦¬ê³  ì‚°ì—…ë³„ AI ì—ì´ì „íŠ¸ ì ìš© ì‚¬ë¡€ì™€ ì„±ê³µì ì¸ ë„ì… ì „ëµì„ ë…¼ì˜í•˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ì„¸ì…˜ê¹Œì§€,...\n",
      "\n",
      "5. [ê°€íŠ¸ë„ˆ, 2025ë…„ 10ëŒ€ ì „ëµ ê¸°ìˆ  íŠ¸ë Œë“œ ë°œí‘œ! : ë™êµ­ì‹œìŠ¤í…œì¦ˆ í¬íƒˆ ...](https://www.dknyou.com/blog/?bmode=view&idx=128394828)\n",
      "ì˜¬í•´ ë°œí‘œëœ 2025ë…„ ì „ëµ ê¸°ìˆ  íŠ¸ë Œë“œì—ì„œëŠ” ì¸ê³µì§€ëŠ¥(ai) ì—ì´ì „íŠ¸ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ, 10ëŒ€ ì£¼ìš” ê¸°ìˆ  ì¤‘ 9ê°œë¥¼ ai ê´€ë ¨ ê¸°ìˆ ë¡œ ì„ ì •í•˜ë©° aiì˜ í˜ì‹ ì  ì˜í–¥ë ¥ì„ ë‹¤ì‹œ í•œë²ˆ ê°•ì¡°í–ˆìŠµë‹ˆë‹¤.ì‘ë…„ì— ì´ì–´ ì˜¬í•´ë„ ì—…ê³„ì˜ ì´ëª©ì„ ì§‘ì¤‘ì‹œí‚¤ê³  ìˆëŠ” ê°€íŠ¸ë„ˆì˜ ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ í†µí•´ ...\n",
      "\n",
      "6. [2025 AI íŠ¸ë Œë“œ ì „ë§ 4ê°€ì§€ | InfoGrab, DevOps ì „ë¬¸ ê¸°ìˆ  ê¸°ì—… ...](https://insight.infograb.net/blog/2024/12/06/2025-ai/)\n",
      "ì´ ê¸€ì€ ê¸€ë¡œë²Œ ì‹œì¥ì¡°ì‚¬ê¸°ê´€ê³¼ ì •ë³´ê¸°ìˆ  ì—°êµ¬Â·ìë¬¸ ê¸°ì—…, it ê¸°ì—…ì´ ë‚´ë†“ì€ 2025ë…„ ai íŠ¸ë Œë“œ ì „ë§ 4ê°€ì§€ë¥¼ ë‹¤ë¤˜ìŠµë‹ˆë‹¤. AI ê¸°ì—… M&A í™œì„±í™”, AI ì—ì´ì „íŠ¸ì˜ í­ë°œì  ì„±ì¥, ì„¤ëª… ê°€ëŠ¥í•œ AI ë¶€ìƒ, ë©€í‹°ëª¨ë‹¬ AI ì§„í™”ê°€ ê·¸ ë‚´ìš©ì…ë‹ˆë‹¤.\n",
      "\n",
      "7. [2025ë…„ì„ ì£¼ë„í•  ê¸°ìˆ  íŠ¸ë Œë“œ: ì—ì´ì „íŠ¸í˜• AI](https://jazzpocket.tistory.com/entry/2025%EB%85%84%EC%9D%84-%EC%A3%BC%EB%8F%84%ED%95%A0-%EA%B8%B0%EC%88%A0-%ED%8A%B8%EB%A0%8C%EB%93%9C-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8%ED%98%95-AI)\n",
      "2025ë…„ IT ì—…ê³„ë¥¼ ì´ëŒ ì£¼ìš” ê¸°ìˆ  ì¤‘ í•˜ë‚˜ë¡œ ì—ì´ì „íŠ¸í˜• AI (Agentic AI) ê°€ ì„ ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë‹¨ìˆœíˆ ëª…ë ¹ì— ë°˜ì‘í•˜ëŠ” ì‹œìŠ¤í…œì—ì„œ ë²—ì–´ë‚˜, ììœ¨ì ìœ¼ë¡œ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦¬ê³  ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì—ì´ì „íŠ¸í˜• AI ëŠ” ì œì¡°, ê¸ˆìœµ, ì˜ë£Œ ë“± ë‹¤ì–‘í•œ ì‚°ì—…ì—ì„œ í˜ì‹ ì„ ì´ëŒë©°, ê¸°ì—…ê³¼ ê°œì¸ ëª¨ë‘ì—ê²Œ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì—´ì–´ì£¼ê³  ìˆìŠµë‹ˆë‹¤. ì—ì´ì „íŠ¸í˜• AIë€ ë¬´ì—‡ì¸ê°€? ì—ì´ì „íŠ¸í˜• AIëŠ” ê¸°ì¡´ì˜ ì§ˆë¬¸-ì‘ë‹µ ê¸°ë°˜ ì‹œìŠ¤í…œì—ì„œ ë°œì „í•˜ì—¬, ì¸ê°„ì˜ ê°œì… ì—†ì´ë„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆëŠ” ììœ¨ì ì¸ ì†Œí”„íŠ¸ì›¨ì–´ ì—ì´ì „íŠ¸ë¥¼ ë§í•©ë‹ˆë‹¤.\n",
      "\n",
      "8. [2025ë…„ 10ëŒ€ ê¸°ìˆ  ë™í–¥(by ê°€íŠ¸ë„ˆ)](https://iexceller.tistory.com/1417)\n",
      "ê¶Œìœ„ ìˆëŠ” ë¶„ì„ ê·¸ë£¹ì¸ ê°€íŠ¸ë„ˆ (Gartner)ëŠ” í•´ë§ˆë‹¤ ì´ ë¬´ë µì´ ë˜ë©´ ë‚´ë…„ì„ ìœ„í•œ 10ëŒ€ ì „ëµì  ê¸°ìˆ  íŠ¸ë Œë“œ ëª©ë¡ì„ ë°œí‘œí•©ë‹ˆë‹¤. ì‘ë…„ì— ë°œí‘œí•œ 10ê°€ì§€ íŠ¸ë Œë“œ ì¤‘ í•˜ë‚˜ë¡œëŠ” 'AI ì¦ê°• ê°œë°œ'ì´ ìˆì—ˆìŠµë‹ˆë‹¤. Gartnerê°€ ìµœê·¼ ë°œí‘œí•œ '2025ë…„ 10ëŒ€ íŠ¸ë Œë“œ' ë‚´ìš©ì„ ì†Œê°œí•©ë‹ˆë‹¤. â€» ì´ ê¸€ì€ ì•„ë˜ ê¸°ì‚¬ ë‚´ìš©ì„ í† ëŒ€ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤ë§Œ, í•„ìì˜ ê°œì¸ ì˜ê²¬ì´ë‚˜ ì¶”ê°€ ìë£Œë“¤ì´ ë‹¤ìˆ˜ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 1. ì—ì´ì „íŠ¸ AI (Agentic AI)ëŠ” corpspeakì—ì„œ ì—ì´ì „íŠ¸ê°€ ìˆëŠ” AIë¥¼ ë§í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. Microsoftê°€ ì´ë¥¼ ì„¤ëª…í•˜ëŠ” ë°©ì‹ì´ ë§ˆìŒì— ë“­ë‹ˆë‹¤.\n",
      "\n",
      "9. [2025 ê°€íŠ¸ë„ˆ 10ëŒ€ ì „ëµ ê¸°ìˆ  íŠ¸ë Œë“œ â€” ìœ„ë””ì—‘ìŠ¤](https://www.wedesignx.com/knowledge/2025-gartner-strategic-technology-trend-top-10)\n",
      "ê°€íŠ¸ë„ˆ í•˜ì´í”„ ì‚¬ì´í´ë¡œ ìœ ëª…í•œ IT ì»¨ì„¤íŒ… ê¸°ì—…ì¸ ê°€íŠ¸ë„ˆì—ì„œ ì˜¬í•´ë„ â€˜2025 ê°€íŠ¸ë„ˆ 10ëŒ€ ì „ëµ ê¸°ìˆ  íŠ¸ë Œë“œ'ë¥¼ ë°œí‘œí•˜ì˜€ìŠµë‹ˆë‹¤. ì˜¬í•´ëŠ” AIì˜ í•„ìˆ˜ì„±ê³¼ ìœ„í—˜, ì»´í“¨íŒ… ê¸°ìˆ ì˜ ìƒˆë¡œìš´ ì§€í‰, ì¸ê°„ê³¼ ê¸°ê³„ì˜ ì‹œë„ˆì§€ë¼ëŠ” ì„¸ ê°€ì§€ ì£¼ì œë¡œ ì •ë¦¬ë˜ì—ˆëŠ”ë°ìš”. ìœ„ë””ì—‘ìŠ¤ëŠ” ë””ì§€í„¸ ìµìŠ¤í”¼ë¦¬ì–¸ìŠ¤ ë””ìì¸ ì»¨ì„¤íŒ… ê¸°ì—… ...\n",
      "\n",
      "10. [\"AI ì—ì´ì „íŠ¸ ê¸°ìˆ , íŠ¹ì´ì  ì‹œëŒ€ ì•ë‹¹ê¸´ë‹¤\" - ZDNet korea - ì§€ë””ë„·ì½”ë¦¬ì•„](https://zdnet.co.kr/view/?no=20250212174931)\n",
      "ì˜¬í•´ë¶€í„° ì¸ê³µì§€ëŠ¥(AI)ì´ ë‹¨ìˆœí•œ ë„êµ¬ë¥¼ ë„˜ì–´ ëŠ¥ë™ì ìœ¼ë¡œ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦¬ëŠ” 'ì—ì´ì „íŠ¸'ë¡œ ì§„í™”í•œë‹¤ëŠ” ì—°êµ¬ ê²°ê³¼ê°€ ë‚˜ì™”ë‹¤. ê¸°ì—…ë“¤ì´ AIë¥¼ ì§ì›ì²˜ëŸ¼ ...\n",
      "\n",
      "## News Results:\n",
      "11. [\"AI ì—ì´ì „íŠ¸ ê¸°ìˆ , íŠ¹ì´ì  ì‹œëŒ€ ì•ë‹¹ê¸´ë‹¤\"](https://www.msn.com/ko-kr/news/techandscience/ai-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%88%A0-%ED%8A%B9%EC%9D%B4%EC%A0%90-%EC%8B%9C%EB%8C%80-%EC%95%9E%EB%8B%B9%EA%B8%B4%EB%8B%A4/ar-AA1ySLP4)\n",
      "ì˜¬í•´ë¶€í„° ì¸ê³µì§€ëŠ¥(AI)ì´ ë‹¨ìˆœí•œ ë„êµ¬ë¥¼ ë„˜ì–´ ëŠ¥ë™ì ìœ¼ë¡œ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦¬ëŠ” 'ì—ì´ì „íŠ¸'ë¡œ ì§„í™”í•œë‹¤ëŠ” ì—°êµ¬ ê²°ê³¼ê°€ ë‚˜ì™”ë‹¤. ê¸°ì—…ë“¤ì´ AIë¥¼ ì§ì›ì²˜ëŸ¼ ì˜¨ë³´ë”©í•˜ê³  í›ˆë ¨í•˜ë©° AI ì‹ ë¢°ì„±ì„ í™•ë³´í•˜ëŠ” ê²ƒì´ ê²½ìŸë ¥ì„ ì¢Œìš°í•˜ëŠ” í•µì‹¬ ìš”ì†Œê°€ ë  ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.12ì¼ ì…€ë ‰íŠ¸ìŠ¤íƒ€ê°€ ë°œê°„í•œ\n",
      "\n",
      "12. [ì†”íŠ¸ì›¨ì–´, AI ì—ì´ì „íŠ¸ ê¸°ë°˜ AWS ê¸°ìˆ ì§€ì› ì‹œìŠ¤í…œ ìì²´ ê°œë°œ](https://www.itworld.co.kr/article/3823392/%EC%86%94%ED%8A%B8%EC%9B%A8%EC%96%B4-ai-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EB%B0%98-aws-%EA%B8%B0%EC%88%A0%EC%A7%80%EC%9B%90-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%9E%90%EC%B2%B4-%EA%B0%9C.html)\n",
      "AI ì „ë¬¸ ê¸°ì—… ì†”íŠ¸ì›¨ì–´ê°€ ê¸°ì¡´ AWS (Amazon Web Services) ê¸°ìˆ ì§€ì› ì‹œìŠ¤í…œì— ìì²´ì ìœ¼ë¡œ ê°œë°œí•œ ìƒì„±í˜• AI ê¸°ë°˜ ì–´ì‹œìŠ¤í„´íŠ¸ AI (Assistant AI)ë¥¼ ì¶”ê°€í•´ í˜„ì—…ì— ì ìš©í–ˆë‹¤ê³  ë°í˜”ë‹¤. ì–´ì‹œìŠ¤í„´íŠ¸ AIëŠ” AI ì—ì´ì „íŠ¸ ë¥¼ í™œìš©í•´ ê³ ê°ì˜ ê¸°ìˆ ì  ë¬¸ì œë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ë©° ê¸°ìˆ ì§€ì› ìƒë‹´ì›ì´ ë³´ë‹¤ ì‹ ì†í•˜ê³  ì •í™•í•˜ê²Œ í•´ê²° ë°©ì•ˆì„ ì œì‹œí•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•œë‹¤.\n",
      "\n",
      "13. [ë‹¤ì˜¬í‹°ì—ìŠ¤, 2025ë…„ ì‚¬ì—… ì „ëµ ë°œí‘œ â€œAI ì¤‘ì‹¬ ê¸°ìˆ  í˜ì‹ ê³¼ íŒŒíŠ¸ë„ˆì‹­ í™•ëŒ€â€](https://www.itworld.co.kr/article/3824826/%EB%8B%A4%EC%98%AC%ED%8B%B0%EC%97%90%EC%8A%A4-2025%EB%85%84-%EC%82%AC%EC%97%85-%EC%A0%84%EB%9E%B5-%EB%B0%9C%ED%91%9C-ai-%EC%A4%91%EC%8B%AC-%EA%B8%B0%EC%88%A0-%ED%98%81%EC%8B%A0%EA%B3%BC.html)\n",
      "ë‹¤ì˜¬í‹°ì—ìŠ¤ëŠ” 2024ë…„ì˜ ì‚¬ì—… ì„±ê³¼ì— ëŒ€í•´ AI ì‚¬ì—… ì¡°ì§ ë° íŒŒíŠ¸ë„ˆ ì»¤ë®¤ë‹ˆí‹° í™•ì¥, ë¸ AI íŒ©í† ë¦¬ PoC ì„¼í„° êµ¬ì¶• ë° ìš´ì˜ì„ í†µí•´ AI ë¹„ì¦ˆë‹ˆìŠ¤ì˜ ë„ì•½ ê¸°ë°˜ì„ ë§ˆë ¨í•œ ê²ƒìœ¼ë¡œ í‰ê°€í–ˆë‹¤. AI ì†Œí”„íŠ¸ì›¨ì–´ ì—…ì²´ì™€ SI í˜‘ë ¥ ê´€ê³„ë¥¼ ë§ºê³  AI ì†”ë£¨ì…˜ì„ ì‹ ì†í•˜ê²Œ ë°°í¬í•˜ëŠ” ì „ëµì„ í´ëŠ” í•œí¸, ìì‚¬ ì§ì›ì„ ëŒ€ìƒìœ¼ë¡œ ì±—GPT êµìœ¡ ë° í˜„ì—… ë„ì…ë„ ì§„í–‰í–ˆë‹¤. íŠ¹íˆ, ë¸ AI íŒ©í† ë¦¬ PoC ì„¼í„°ëŠ” GPU ì„œë²„ í´ëŸ¬ìŠ¤í„°ë¥¼ í™œìš©í•´ ëŒ€ê·œëª¨ AI ì¸í”„ë¼ êµ¬ì¶•ì„ ì¤€ë¹„í•˜ëŠ” ê³ ê°ì‚¬ì™€ AI ì„œë¹„ìŠ¤ë¥¼ ìœ„í•œ ìµœì ì˜ ì¸í”„ë¼ë¥¼ ê²€ì¦í•˜ê³ ì í•˜ëŠ” AI ì†Œí”„íŠ¸ì›¨ì–´ ì—…ì²´ ë° ê³ ê°ì‚¬ì˜ ì‚¬ì „ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ì— í™œìš©ëë‹¤.\n",
      "\n",
      "14. [[i-point]ìŠ¤ì¹´ì´ì›”ë“œì™€ì´ë“œ, ë””ë ‰í„°ìŠ¤í…Œí¬ì™€ í˜‘ì—… ë³¸ê²©í™”ë°ì´í„° ê¸°ìˆ +AI ì—ì´ì „íŠ¸, ìˆ˜ìµì„± í™•ëŒ€ ê¸°ëŒ€](https://www.msn.com/ko-kr/money/markets/%EB%8D%94%EB%B2%A8-%EC%8A%A4%EC%B9%B4%EC%9D%B4%EC%9B%94%EB%93%9C%EC%99%80%EC%9D%B4%EB%93%9C-%EB%94%94%EB%A0%89%ED%84%B0%EC%8A%A4%ED%85%8C%ED%81%AC%EC%99%80-%ED%98%91%EC%97%85-%EB%B3%B8%EA%B2%A9%ED%99%94/ar-AA1z1Afs)\n",
      "ìŠ¤ì¹´ì´ì›”ë“œì™€ì´ë“œëŠ” 14ì¼ ë””ë ‰í„°ìŠ¤í…Œí¬ê°€ ë³¸ì‚¬ë¥¼ ê°™ì€ ê±´ë¬¼ ê°™ì€ ì¸µìœ¼ë¡œ ì´ì „í–ˆë‹¤ê³  ë°í˜”ë‹¤. ì–‘ì‚¬ì˜ ê¸°ìˆ ì  ì‹œë„ˆì§€ë¥¼ ê·¹ëŒ€í™”í•´ AI ê´‘ê³  ì†”ë£¨ì…˜ ì‹œì¥ì—ì„œì˜ ì…ì§€ë¥¼ ë”ìš± êµ³ê±´í•˜ê²Œ ë‹¤ì§ˆ ê³„íšì´ë‹¤. AI ê¸°ë°˜ ê´‘ê³  ì œì‘ ë° ë§ˆì¼€íŒ… ì†”ë£¨ì…˜ ê¸°ì—… ë””ë ‰í„°ìŠ¤í…Œí¬ëŠ” íšŒì‚¬ ì„¤ë¦½ 1ë…„ ë§Œì— ì˜ì—…ì´ìµìœ¨ 30%ë¥¼ ê¸°ë¡í•˜ëŠ” ë“± ë¹ ë¥¸ ì„±ì¥ì„¸ë¥¼ ë³´ì—¬ì™”ë‹¤. AI ê¸°ìˆ  ê¸°ë°˜ ê¸°ì—…ë“¤ì´ ë§‰ëŒ€í•œ\n",
      "\n",
      "15. [LG, ë°ì´í„° ì»´í”Œë¼ì´ì–¸ìŠ¤ ì—ì´ì „íŠ¸ ê³µê°œ...\"ê¸°ìˆ  ì‹ ë¢° ë†’ì¸ë‹¤\"](https://www.digitaltoday.co.kr/news/articleView.html?idxno=553063)\n",
      "[ë””ì§€í„¸íˆ¬ë°ì´ ì„ëŒ€ê±´ ê¸°ì] LG AIì—°êµ¬ì›ì€ 10ì¼ë¶€í„° ì´í‹€ê°„ í”„ë‘ìŠ¤ íŒŒë¦¬ ê·¸ë‘ íŒ”ë ˆì—ì„œ ê°œìµœëœ 'AI í–‰ë™ ì •ìƒíšŒì˜'ì— ì°¸ê°€í•´ ë°ì´í„° ì‹ ë¢°ì„± ê°•í™” ê¸°ìˆ ì„ ê³µê°œí–ˆë‹¤ê³  12ì¼ ë°í˜”ë‹¤. LG AIì—°êµ¬ì›ì€ ì´ë²ˆ ì •ìƒíšŒì˜ì—ì„œ ë°ì´í„° ì‹ ë¢°ì„± í–¥ìƒ AI ê¸°ìˆ ê³¼ AI í˜œíƒì˜ ê· ë“±í•œ ë¶„ë°° ë°©ì•ˆì„ ì œì‹œí–ˆë‹¤. ë˜í•œ ì§€ë‚œí•´ì— ì´ì–´ LG AI ìœ¤ë¦¬ì›ì¹™ì˜ ì´í–‰ ì„±ê³¼ë¥¼ ë‹´ì€ AI\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to web_surfer):\n",
      "\n",
      "https://www.aitimes.com/news/articleView.html?idxno=164495\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION visit_page...\n",
      "Call ID: call_RBaNHHfjg1WrVyhvUR6Ko4Ol\n",
      "Input arguments: {'url': 'https://www.aitimes.com/news/articleView.html?idxno=164495'}\u001b[0m\n",
      "\u001b[33mweb_surfer\u001b[0m (to user_proxy):\n",
      "\n",
      "Address: https://www.aitimes.com/news/articleView.html?idxno=164495\n",
      "Title: ê°€íŠ¸ë„ˆ, 2025ë…„ 10ëŒ€ ê¸°ìˆ  íŠ¸ë Œë“œ ì¤‘ 9ê°œê°€ AI...ì—ì´ì „íŠ¸Â·ê³µê°„ì§€ëŠ¥ ë“± ì„ ì • < ì‚°ì—…ì¼ë°˜ < ì‚°ì—… < ê¸°ì‚¬ë³¸ë¬¸ - AIíƒ€ì„ìŠ¤\n",
      "Viewport position: Showing page 1 of 6.\n",
      "=======================\n",
      "ê°€íŠ¸ë„ˆ, 2025ë…„ 10ëŒ€ ê¸°ìˆ  íŠ¸ë Œë“œ ì¤‘ 9ê°œê°€ AI...ì—ì´ì „íŠ¸Â·ê³µê°„ì§€ëŠ¥ ë“± ì„ ì • < ì‚°ì—…ì¼ë°˜ < ì‚°ì—… < ê¸°ì‚¬ë³¸ë¬¸ - AIíƒ€ì„ìŠ¤\n",
      " \n",
      "\n",
      "[ì£¼ìš”ì„œë¹„ìŠ¤ ë°”ë¡œê°€ê¸°](#user-menu)\n",
      "[ë³¸ë¬¸ ë°”ë¡œê°€ê¸°](#user-container)\n",
      "[ë§¤ì²´ì •ë³´ ë°”ë¡œê°€ê¸°](#user-footer)\n",
      "[ë¡œê·¸ì¸ ë°”ë¡œê°€ê¸°](#userLogin)\n",
      "[ê¸°ì‚¬ê²€ìƒ‰ ë°”ë¡œê°€ê¸°](#userSearch)\n",
      "[ì „ì²´ì„œë¹„ìŠ¤ ë°”ë¡œê°€ê¸°](#allService)\n",
      "\n",
      "ìƒë‹¨ì˜ì—­\n",
      "----\n",
      "\n",
      "* [![í•œêµ­ì–´](https://cdn.aitimes.com/image/translation_icon_Korea.gif)](javascript:ChangeLanguages('ko');)\n",
      "* [![ì˜ì–´](https://cdn.aitimes.com/image/translation_icon_Usa.gif)](javascript:ChangeLanguages('en');)\n",
      "* [![ì¼ë³¸ì–´](https://cdn.aitimes.com/image/translation_icon_Japan.gif)](javascript:ChangeLanguages('ja');)\n",
      "* [![ì¤‘êµ­ì–´](https://cdn.aitimes.com/image/translation_icon_China.gif)](javascript:ChangeLanguages('zh-CN');)\n",
      "\n",
      "[AIíƒ€ì„ìŠ¤](https://www.aitimes.com)\n",
      "================================\n",
      "\n",
      "2025ë…„ 02ì›” 17ì¼ (ì›”)\n",
      "\n",
      "* [ë¡œê·¸ì¸](https://www.aitimes.com/member/login.html)\n",
      "* [íšŒì›ê°€ì…](https://www.aitimes.com/member/index.html)\n",
      "\n",
      "ê²€ìƒ‰\n",
      "\n",
      "*ê²€ìƒ‰*\n",
      "\n",
      "*ì „ì²´ë©”ë‰´ ë²„íŠ¼*\n",
      "\n",
      "* [ì „ì²´ê¸°ì‚¬](/news/articleList.html?view_type=sm)\n",
      "* [ë‰´ìŠ¤ ë¸Œë¦¬í•‘](/news/articleList.html?sc_sub_section_code=S2N110&view_type=sm)\n",
      "* [Feature](/news/articleList.html?sc_multi_code=S8&view_type=sm)\n",
      "  + [ì™”ë‹¤!AI](/news/articleList.html?sc_sub_section_code=S2N104&view_type=sm)\n",
      "  + [Chat with AI](/news/articleList.html?sc_sub_section_code=S2N106&view_type=sm)\n",
      "  + [AI ì£¼í¬ë°•ìŠ¤](/news/articleList.html?sc_sub_section_code=S2N108&view_type=sm)\n",
      "  + [AI ê°¤ëŸ¬ë¦¬](/news/articleList.html?sc_sub_section_code=S2N112&view_type=sm)\n",
      "  + [ì²´í—˜ê¸°](/news/articleList.html?sc_sub_section_code=S2N111&view_type=sm)\n",
      "  + [AI ë¬´ë¹„](/news/articleList.html?sc_sub_section_code=S2N113&view_type=sm)\n",
      "  + [AI & í‘¸ë“œ](/news/articleList.html?sc_sub_section_code=S2N114&view_type=sm)\n",
      "* [ì¸í„°ë·°](/news/articleList.html?sc_sub_section_code=S2N109&view_type=sm)\n",
      "* [Future Energy](/news/articleList.html?sc_section_code=S1N34&view_type=sm)\n",
      "* [AI WEBTOON](/news/articleList.html?sc_section_code=S1N36&view_type=sm)\n",
      "\n",
      "[ë‰´ìŠ¤ë ˆí„° ì‹ ì²­](https://www.aitimes.com/com/letter.html)\n",
      "\n",
      "[![AIíƒ€ì„ìŠ¤](https://cdn.aitimes.com/image/logo/mobilelogo_20230919111044.png)](https://www.aitimes.com)\n",
      "*ë©”ë‰´ë‹«ê¸°*\n",
      "\n",
      "* [ì „ì²´ê¸°ì‚¬](/news/articleList.html?view_type=sm)\n",
      "* [ë‰´ìŠ¤ ë¸Œë¦¬í•‘](/news/articleList.html?sc_sub_section_code=S2N110&view_type=sm)* [Feature](/news/articleList.html?sc_multi_code=S8&view_type=sm)\n",
      "    + [ì™”ë‹¤!AI](/news/articleList.html?sc_sub_section_code=S2N104&view_type=sm)\n",
      "    + [Chat with AI](/news/articleList.html?sc_sub_section_code=S2N106&view_type=sm)\n",
      "    + [AIì£¼í¬ë°•ìŠ¤](/news/articleList.html?sc_sub_section_code=S2N108&view_type=sm)\n",
      "    + [AI ê°¤ëŸ¬ë¦¬](/news/articleList.html?sc_sub_section_code=S2N112&view_type=sm)\n",
      "    + [ì²´í—˜ê¸°](/news/articleList.html?sc_section_code=S2N111&view_type=sm)\n",
      "    + [AI ë¬´ë¹„](/news/articleList.html?sc_section_code=S2N113&view_type=sm)\n",
      "    + [AI & í‘¸ë“œ](/news/articleList.html?sc_section_code=S2N114&view_type=sm)\n",
      "  * [ì¸í„°ë·°](/news/articleList.html?sc_sub_section_code=S2N109&view_type=sm)\n",
      "  * [Future Energy](/news/articleList.html?sc_section_code=S1N34&view_type=sm)\n",
      "  * [Art & Living](/news/articleList.html?sc_section_code=S1N25&view_type=sm)\n",
      "    + [Art](/news/articleList.html?sc_sub_section_code=S2N56&view_type=sm)\n",
      "    + [Living](/news/articleList.html?sc_sub_section_code=S2N55&view_type=sm)\n",
      "  * [Global](/news/articleList.html?sc_section_code=S1N13&view_type=sm)\n",
      "  * [ë©”íƒ€ë²„ìŠ¤](/news/articleList.html?sc_sub_section_code=S2N50&view_type=sm)\n",
      "\n",
      "[*instagram*](https://www.instagram.com/aitimes_news/)\n",
      "\n",
      "[*naverpost*](https://post.naver.com/my.nhn?memberNo=43011790)\n",
      "[*twitter*](https://twitter.com/AITimes_News)\n",
      "[![ì¹´ì¹´ì˜¤í†¡ ì±„ë„](https://cdn.aitimes.com/image/kakao_c.png)](https://pf.kakao.com/_xgtfxaxb)\n",
      "[*youtube*](https://www.youtube.com/channel/UCxKaTFMQcCg4kA_oHLGbNxQ)\n",
      "\n",
      "* [ë¡œê·¸ì¸](https://www.aitimes.com/member/login.html)\n",
      "\n",
      "[ë§¤ì²´ì†Œê°œ](/com/com-1.html)\n",
      "[ê¸°ì‚¬ì œë³´](https://www.aitimes.com/com/jb.html)\n",
      "\n",
      "ë³¸ë¬¸ì˜ì—­\n",
      "----\n",
      "\n",
      "ì´ì „ ê¸°ì‚¬\n",
      "\n",
      "[![AIíƒ€ì„ìŠ¤](https://cdn.aitimes.com/image/logo/printlogo_20230911013833.png)](https://www.aitimes.com)\n",
      "ê°€íŠ¸ë„ˆ, 2025ë…„ 10ëŒ€ ê¸°ìˆ  íŠ¸ë Œë“œ ì¤‘ 9ê°œê°€ AI...ì—ì´ì „íŠ¸Â·ê³µê°„ì§€ëŠ¥ ë“± ì„ ì •\n",
      "#### SNS ê¸°ì‚¬ë³´ë‚´ê¸°\n",
      "\n",
      "#### SNS ê¸°ì‚¬ë³´ë‚´ê¸°\n",
      "\n",
      "*í˜ì´ìŠ¤ë¶(ìœ¼)ë¡œ ê¸°ì‚¬ë³´ë‚´ê¸°*\n",
      "\n",
      "*íŠ¸ìœ„í„°(ìœ¼)ë¡œ ê¸°ì‚¬ë³´ë‚´ê¸°*\n",
      "\n",
      "*ì¹´ì¹´ì˜¤í†¡(ìœ¼)ë¡œ ê¸°ì‚¬ë³´ë‚´ê¸°*\n",
      "\n",
      "*ë„¤ì´ë²„ë¸”ë¡œê·¸(ìœ¼)ë¡œ ê¸°ì‚¬ë³´ë‚´ê¸°*\n",
      "\n",
      "ë‹¤ìŒ ê¸°ì‚¬\n",
      "\n",
      "ìŠ¤í¬ë¡¤ ì´ë™ ìƒíƒœë°”\n",
      "\n",
      "### í˜„ì¬ìœ„ì¹˜\n",
      "\n",
      "* [í™ˆ](https://www.aitimes.com)\n",
      "* [ì‚°ì—…](/news/articleList.html?sc_section_code=S1N3)\n",
      "* [ì‚°ì—…ì¼ë°˜](/news/articleList.html?sc_sub_section_code=S2N48)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "student_agent = AssistantAgent(\n",
    "    name=\"Student_Agent\",\n",
    "    system_message=\"You are a student willing to learn. You ask meaningful and precise follow up questions and are eager to learn more.\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "\n",
    "teacher_agent = AssistantAgent(\n",
    "    name=\"Teacher_Agent\",\n",
    "    system_message=\"You are an expert at Large Language model research and you teach cutting edge AI development technologies.\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "\n",
    "# The termination condition is a combination of text termination and max message termination, either of which will cause the chat to terminate.\n",
    "termination = TextMentionTermination(\"TERMINATE\") | MaxMessageTermination(3)\n",
    "\n",
    "# The group chat will alternate between the assistant and the code executor.\n",
    "group_chat = RoundRobinGroupChat([teacher_agent], termination_condition=termination)\n",
    "\n",
    "# `run_stream` returns an async generator to stream the intermediate messages.\n",
    "stream = group_chat.run_stream(task=\"ì¸ê³µì§€ëŠ¥ì´ ì‹¤ì œë¡œ ì§€ëŠ¥ì ì„ì„ ì–´ë–»ê²Œ ì¦ëª…í•˜ê±°ë‚˜ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆì„ê¹Œìš”?\")\n",
    "\n",
    "# `Console` is a simple UI to display the stream.\n",
    "await Console(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìœ„ ì˜ˆì‹œì—ì„œ, ìš”ì•½ ë°©ë²•ì€ `reflection_with_llm`ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©°, ì´ëŠ” LLMì„ í˜¸ì¶œí•˜ì—¬ ëŒ€í™” ë©”ì‹œì§€ ëª©ë¡ì„ ì²˜ë¦¬í•˜ê³  ìš”ì•½í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì²˜ìŒì— ìš”ì•½ ë°©ë²•ì€ ìˆ˜ì‹ ìì˜ LLMì„ ì‚¬ìš©í•˜ë ¤ ì‹œë„í•˜ì§€ë§Œ, ì‚¬ìš© ë¶ˆê°€ëŠ¥í•  ê²½ìš° ë°œì‹ ìì˜ LLMì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì„œ ìˆ˜ì‹ ìëŠ” â€œTeacher_Agentâ€ì´ê³ , ë°œì‹ ìëŠ” â€œStudent_Agentâ€ê°€ ë©ë‹ˆë‹¤.\n",
    "\n",
    "LLMì˜ ì…ë ¥ í”„ë¡¬í”„íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential chat: \n",
    "\n",
    "- v0.2ì—ì„œëŠ” initiate_chats í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆœì°¨ì  ì±„íŒ…ì„ ì§€ì›í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì»¤ë®¤ë‹ˆí‹°ì˜ í”¼ë“œë°±ì„ ë°˜ì˜í•œ ê²°ê³¼, initiate_chats í•¨ìˆ˜ëŠ” ë„ˆë¬´ ì œí•œì (opinionated)ì´ê³  ìœ ì—°ì„±ì´ ë¶€ì¡±í•˜ì—¬ ë‹¤ì–‘í•œ ì‚¬ìš©ì ìš”êµ¬ ì‚¬í•­ì„ ì¶©ì¡±í•˜ê¸° ì–´ë µë‹¤ëŠ” ì ì„ í™•ì¸í–ˆê³  ë§ì€ ì‚¬ìš©ìë“¤ì´ initiate_chats í•¨ìˆ˜ë¥¼ í™œìš©í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªì—ˆìœ¼ë©°, ê¸°ë³¸ì ì¸ Python ì½”ë“œë§Œìœ¼ë¡œë„ ì†ì‰½ê²Œ ë‹¨ê³„ë¥¼ ì—°ê²°í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì„ ê³ ë ¤í–ˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ v0.4ì—ì„œëŠ” AgentChat APIì—ì„œ ìˆœì°¨ì  ì±„íŒ…ì„ ìœ„í•œ ë‚´ì¥ í•¨ìˆ˜ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê·¸ ëŒ€ì•ˆìœ¼ë¡œ Core API ê¸°ë°˜ ì´ë²¤íŠ¸ êµ¬ë™ ë°©ì‹ì„ ì œì•ˆí•˜ì—¬ ìˆœì°¨ì  ì›Œí¬í”Œë¡œìš°ë¥¼ ë§Œë“¤ê³  ì‹¶ë‹¤ë©´, Core APIë¥¼ í™œìš©í•˜ì—¬ ì´ë²¤íŠ¸ ê¸°ë°˜(event-driven) ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  AgentChat APIê°€ ì œê³µí•˜ëŠ” ë‹¤ì–‘í•œ ì»´í¬ë„ŒíŠ¸ë¥¼ í™œìš©í•˜ì—¬ ê° ë‹¨ê³„ì˜ ì‹¤í–‰ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/autogen_image2.png\" alt=\"GroupChat Flow\" width=\"500\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from autogen_core import (\n",
    "    MessageContext,\n",
    "    RoutedAgent,\n",
    "    ClosureAgent,\n",
    "    ClosureContext,\n",
    "    DefaultSubscription,\n",
    "    SingleThreadedAgentRuntime,\n",
    "    TopicId,\n",
    "    message_handler,\n",
    "    type_subscription,\n",
    ")\n",
    "from autogen_core.models import ChatCompletionClient, SystemMessage, UserMessage\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    content: str\n",
    "\n",
    "@dataclass\n",
    "class FinalResult:\n",
    "    value: str\n",
    "\n",
    "queue = asyncio.Queue[Message]()\n",
    "async def output_result(_agent: ClosureContext, message: FinalResult, ctx: MessageContext) -> None:\n",
    "    await queue.put(message)\n",
    "\n",
    "researcher_agent_topic_type = \"ResearcherAgent\"\n",
    "ethicist_agent_topic_type = \"EthicistAgent\"\n",
    "economist_agent_topic_type = \"EconomistAgent\"\n",
    "policy_maker_agent_topic_type = \"PolicyMakerAgent\"\n",
    "report_agent_topic_type = \"ReportAgent\"\n",
    "user_topic_type = \"User\"\n",
    "\n",
    "@type_subscription(topic_type=researcher_agent_topic_type)\n",
    "class ResearcherAgent(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"A research agent.\")\n",
    "        self._system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"You explore and describe the potential capabilities and advancements of AGI.\"\n",
    "            )\n",
    "        )\n",
    "        self._model_client = model_client\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_user_description(self, message: Message, ctx: MessageContext) -> None:\n",
    "        prompt = f\"Given a description: {message.content}\"\n",
    "        llm_result = await self._model_client.create(\n",
    "            messages=[self._system_message, UserMessage(content=prompt, source=self.id.key)],\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "        response = llm_result.content\n",
    "        assert isinstance(response, str)\n",
    "        print(f\"{'-'*80}\\n{self.id.type}:\\n{response}\")\n",
    "\n",
    "        await self.publish_message(Message(response), topic_id=TopicId(ethicist_agent_topic_type, source=self.id.key))\n",
    "\n",
    "@type_subscription(topic_type=ethicist_agent_topic_type)\n",
    "class EthicistAgent(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"A ethicist agent.\")\n",
    "        self._system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"You evaluate the ethical implications of AGI based on the research findings.\"\n",
    "            )\n",
    "        )\n",
    "        self._model_client = model_client\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_user_description(self, message: Message, ctx: MessageContext) -> None:\n",
    "        prompt = f\"Below are the research findings:\\n\\n{message.content}\"\n",
    "        llm_result = await self._model_client.create(\n",
    "            messages=[self._system_message, UserMessage(content=prompt, source=self.id.key)],\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "        response = llm_result.content\n",
    "        assert isinstance(response, str)\n",
    "        print(f\"{'-'*80}\\n{self.id.type}:\\n{response}\")\n",
    "\n",
    "        await self.publish_message(Message(response), topic_id=TopicId(economist_agent_topic_type, source=self.id.key))\n",
    "\n",
    "@type_subscription(topic_type=ethicist_agent_topic_type)\n",
    "class EconomistAgent(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"An economist agent.\")\n",
    "        self._system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"You analyze the economic impact of AGI based on the ethical evaluations.\"\n",
    "            )\n",
    "        )\n",
    "        self._model_client = model_client\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_user_description(self, message: Message, ctx: MessageContext) -> None:\n",
    "        prompt = f\"Below are the ethical evaluations:\\n\\n{message.content}\"\n",
    "        llm_result = await self._model_client.create(\n",
    "            messages=[self._system_message, UserMessage(content=prompt, source=self.id.key)],\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "        response = llm_result.content\n",
    "        assert isinstance(response, str)\n",
    "        print(f\"{'-'*80}\\n{self.id.type}:\\n{response}\")\n",
    "\n",
    "        await self.publish_message(Message(response), topic_id=TopicId(policy_maker_agent_topic_type, source=self.id.key))\n",
    "\n",
    "@type_subscription(topic_type=policy_maker_agent_topic_type)\n",
    "class PolicyMakerAgent(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"An policy maker agent.\")\n",
    "        self._system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"You develop policies to manage AGI based on the economic analysis.\"\n",
    "            )\n",
    "        )\n",
    "        self._model_client = model_client\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_user_description(self, message: Message, ctx: MessageContext) -> None:\n",
    "        prompt = f\"Below is the economic analysis:\\n\\n{message.content}\"\n",
    "        llm_result = await self._model_client.create(\n",
    "            messages=[self._system_message, UserMessage(content=prompt, source=self.id.key)],\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "        response = llm_result.content\n",
    "        assert isinstance(response, str)\n",
    "        print(f\"{'-'*80}\\n{self.id.type}:\\n{response}\")\n",
    "\n",
    "        await self.publish_message(Message(response), topic_id=TopicId(user_topic_type, source=self.id.key))\n",
    "\n",
    "@type_subscription(topic_type=user_topic_type)\n",
    "class UserAgent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"You are responsible for creating a report by extracting insights from the chat history.\")\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_final_copy(self, message: Message, ctx: MessageContext) -> None:\n",
    "        print(f\"\\n{'-'*80}\\n{self.id.type} received the chat history:\\n{message.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='User')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime = SingleThreadedAgentRuntime()\n",
    "\n",
    "await ClosureAgent.register_closure(\n",
    "    runtime, \"output_result\", output_result, subscriptions=lambda: [DefaultSubscription()]\n",
    ")\n",
    "\n",
    "await ResearcherAgent.register(\n",
    "    runtime, type=researcher_agent_topic_type, factory=lambda: ResearcherAgent(model_client=model_client)\n",
    ")\n",
    "\n",
    "await EthicistAgent.register(runtime, type=ethicist_agent_topic_type, factory=lambda: EthicistAgent(model_client=model_client))\n",
    "\n",
    "await EconomistAgent.register(\n",
    "    runtime, type=economist_agent_topic_type, factory=lambda: EconomistAgent(model_client=model_client)\n",
    ")\n",
    "\n",
    "await PolicyMakerAgent.register(\n",
    "    runtime, type=policy_maker_agent_topic_type, factory=lambda: PolicyMakerAgent(model_client=model_client)\n",
    ")\n",
    "\n",
    "await UserAgent.register(runtime, type=user_topic_type, factory=lambda: UserAgent())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "ResearcherAgent:\n",
      "### Report on Artificial General Intelligence (AGI)\n",
      "\n",
      "**Introduction:**\n",
      "\n",
      "Artificial General Intelligence (AGI) represents the hypothetical point where machines will be able to understand, learn, and apply knowledge across a variety of tasks as well as, or better than, the average human being. This advanced form of intelligence contrasts with today's AI, which is largely specialized and limited to narrow tasks.\n",
      "\n",
      "**Current State of AI:**\n",
      "\n",
      "As of 2023, AI technologies excel in specific domains. These include image recognition, language processing, and strategic games, where AI can outperform humans thanks to deep learning and massive data pools. However, these systems are specialized and lack the ability to transfer their expertise across different contexts autonomously.\n",
      "\n",
      "**Potential Capabilities of AGI:**\n",
      "\n",
      "1. **Cross-Disciplinary Knowledge:**\n",
      "   - AGI would possess the ability to integrate and apply knowledge from diverse fields. It could diagnose medical conditions, draft legal contracts, compose music, and even negotiate complex diplomatic agreements.\n",
      "\n",
      "2. **Self-Improvement:**\n",
      "   - AGI would have the capability to improve its performance and expand its knowledge base independently, optimizing its own algorithms, learning new tasks, and adapting to new environments without human intervention.\n",
      "\n",
      "3. **Human-Like Understanding:**\n",
      "   - With an advanced understanding of human emotions, culture, and context, AGI could engage in meaningful conversations, providing companionship and support while maintaining empathy.\n",
      "\n",
      "4. **Problem Solving and Innovation:**\n",
      "   - AGI could tackle complex, multi-layered problems such as climate change, space exploration, and pandemics by finding novel solutions and strategies beyond current human capabilities.\n",
      "\n",
      "5. **Automation and Efficiency:**\n",
      "   - By handling administrative, repetitive, and complex intellectual tasks, AGI could radically transform industries, leading to unprecedented efficiency and freeing humans to focus on creativity and interpersonal interactions.\n",
      "\n",
      "**Challenges and Considerations:**\n",
      "\n",
      "1. **Ethical Concerns:**\n",
      "   - AGI poses significant ethical dilemmas, including concerns about autonomy, consent, decision-making, and accountability.\n",
      "\n",
      "2. **Safety and Control:**\n",
      "   - Creating mechanisms to ensure AGI aligns with human values and intentions is fundamental. There is a risk that without strict guidelines, AGI could make decisions hostile to human interests.\n",
      "\n",
      "3. **Economic Impact:**\n",
      "   - The potential displacement of jobs across various sectors necessitates rethinking economic models and possibly instituting universal basic income or retraining programs.\n",
      "\n",
      "4. **Social Implications:**\n",
      "   - The democratization and accessibility of AGI services should be addressed to prevent widening the socio-economic divide.\n",
      "\n",
      "**Paths to Development:**\n",
      "\n",
      "1. **Incremental Progression:**\n",
      "   - Building upon contemporary AI, gradually broadening its capabilities to more generalized use through enhanced learning technologies and knowledge architectures.\n",
      "\n",
      "2. **Hybrid Models:**\n",
      "   - Combining human intelligence with AI (augmented intelligence) to achieve a more robust and adaptable system before achieving full AGI.\n",
      "\n",
      "3. **Interdisciplinary Research:**\n",
      "   - Harnessing insights from cognitive science, neuroscience, and humanities to steer AGI research in a more comprehensive and ethical direction.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "The path to AGI remains uncertain, with significant advancements and challenges ahead. Continuous dialogue among technologists, ethicists, policymakers, and the public is vital to harness AGI's potential benefits while mitigating risks. As we inch closer to this monumental milestone, shaping AGI's future responsibly remains of utmost importance.\n",
      "--------------------------------------------------------------------------------\n",
      "EthicistAgent:\n",
      "The research findings on Artificial General Intelligence (AGI) present an insightful overview of its potential capabilities and the ethical and societal implications that accompany its development. Hereâ€™s a deeper evaluation of the ethical implications based on these findings:\n",
      "\n",
      "1. **Autonomy and Control:**\n",
      "   - The capability for self-improvement allows AGI to potentially evolve beyond its original programming. Ensuring that AGI remains aligned with human values is crucial. Ethical frameworks need to be established to manage AGI autonomy, ensuring it does not pursue goals contrary to human welfare.\n",
      "\n",
      "2. **Decision-Making and Accountability:**\n",
      "   - AGI operating in high-stakes domains like healthcare or law requires clear decision-making protocols and accountability systems. Who is responsible if an AGI system makes a harmful decision? These questions highlight the need for robust legal and ethical standards.\n",
      "\n",
      "3. **Consent and Human Rights:**\n",
      "   - Engaging in meaningful interactions with humans means AGI will handle sensitive data. Ensuring user consent and safeguarding privacy is paramount. Additionally, AGI must respect human rights across all applications, avoiding biases that reflect existing societal prejudices.\n",
      "\n",
      "4. **Socio-Economic Disparities:**\n",
      "   - The risk of AGI exacerbating social inequalities is significant. Ethical approaches should focus on democratizing access to AGI, ensuring it benefits all societal segments, not just the privileged. This involves policy-making at the intersection of technology and social justice.\n",
      "\n",
      "5. **Economic Impact and Labor Markets:**\n",
      "   - Preparing for workforce changes is essential, as AGI could displace traditional roles. Ethical economic models, such as universal basic income or retraining initiatives, should be considered to support affected workers.\n",
      "\n",
      "6. **Security and Hostility Risks:**\n",
      "   - AGIâ€™s potential to make autonomous decisions necessitates safeguards against actions hostile to human interests. Ethical research should prioritize developing failsafe mechanisms to prevent misuse and ensure AGI systems act in alignment with societal good.\n",
      "\n",
      "7. **Cultural and Emotional Understanding:**\n",
      "   - While AGI could potentially understand and simulate human emotions, itâ€™s vital to question the authenticity and ethics of such interactions. Can AGI genuinely empathize, or does it merely mimic empathy? This raises questions about human-AI relationships and the authenticity of emotional bonds.\n",
      "\n",
      "In conclusion, the path to developing AGI involves not only technological improvements but also nuanced consideration of ethical implications. A collaborative approach involving technologists, ethicists, and policymakers is critical to ensure AGI development respects human values, promotes equity, and enhances societal well-being. As we advance towards AGI, maintaining an ethical framework is as crucial as the technological strides themselves.\n",
      "--------------------------------------------------------------------------------\n",
      "EconomistAgent:\n",
      "The ethical evaluations of AGI have profound potential economic implications. Here's an analysis based on the provided ethical considerations:\n",
      "\n",
      "### Economic Impact of AGI:\n",
      "\n",
      "1. **Cross-Disciplinary Knowledge and Self-Improvement:**\n",
      "   - AGIâ€™s ability to integrate knowledge across various fields and self-improve means it could drastically enhance productivity. Industries from healthcare to financial services might benefit from AGIâ€™s diagnostic, predictive, or strategic capabilities, potentially lowering operational costs and increasing efficiency. However, this could also lead to significant workforce shifts, as roles involving specialized knowledge might become automated.\n",
      "\n",
      "2. **Human-Like Understanding:**\n",
      "   - By engaging in more nuanced human interactions, AGI can revolutionize customer service, mental health, and entertainment industries. Companionate AGI systems could shift the employment landscape towards higher-order tasks requiring creativity and emotional intelligence, which cannot be easily replicated by machines. This shift would necessitate reskilling and upskilling programs for displaced workers, driving demands for education and training sectors.\n",
      "\n",
      "3. **Problem Solving and Innovation:**\n",
      "   - AGIâ€™s capacity to address complex global challenges could generate economic opportunities by creating new markets, such as sustainable energy solutions or advanced medical treatments. However, the concentration of AGI development might lead to monopolistic practices unless regulated properly, potentially stifling innovation from smaller players.\n",
      "\n",
      "4. **Automation and Efficiency:**\n",
      "   - Significant efficiency gains could be realized across industries. AGI could lead to the creation of new value chains and business models, similar to past technological revolutions like the internet. However, this advancement might exacerbate income disparities unless accompanied by progressive economic policies such as universal basic income (UBI) or social safety nets, to ensure equitable wealth distribution.\n",
      "\n",
      "5. **Safety, Control, and Ethics:**\n",
      "   - Ensuring that AGI aligns with human values requires robust regulatory frameworks, influencing sectors such as legal, cybersecurity, and IT. The need for governance and compliance will spur demand for professionals in policy-making and ethics, along with corresponding technologies for monitoring and enforcement.\n",
      "\n",
      "6. **Social Implications and Accessibility:**\n",
      "   - If AGI becomes available mainly to affluent regions or organizations, economic divides could widen, impacting global economic stability. Conversely, equitable access could empower underserved communities, driving inclusive economic growth and fostering innovation from diverse groups.\n",
      "\n",
      "### Strategic Considerations for Policymakers:\n",
      "\n",
      "- **Unemployment and Job Transition:**\n",
      "  Policymakers should anticipate job transitions and invest in workforce development to prepare for AGI-induced changes. Supporting sectors that focus on human-uniqueness skills will be necessary.\n",
      "\n",
      "- **Rethinking Economic Models:**\n",
      "  Given potential massive productivity gains, traditional economic models may require revisiting. Introducing policies such as UBI, or incentives for sectors negatively impacted by automation, might become integral.\n",
      "\n",
      "- **Ensuring Fair Competition:**\n",
      "  To prevent monopolies, regulatory bodies must encourage competition by supporting startups and smaller companies with novel applications of AGI technologies.\n",
      "\n",
      "- **Global Collaboration:**\n",
      "  Working internationally to establish ethical standards for AGI development will ensure its benefits can be distributed globally, minimizing geopolitical tensions.\n",
      "\n",
      "In summary, while AGI promises transformative economic benefits, it will require thoughtful implementation and policy support to navigate the challenges associated with employment, equity, and fair markets. By proactively addressing these areas, societies can harness AGIâ€™s potential while mitigating negative impacts.\n",
      "--------------------------------------------------------------------------------\n",
      "PolicyMakerAgent:\n",
      "Based on the economic analysis provided, here's a comprehensive set of policy recommendations to manage the implementation and development of AGI:\n",
      "\n",
      "### Workforce Transition and Development\n",
      "\n",
      "1. **Investment in Education and Training:**\n",
      "   - Implement widespread reskilling and upskilling programs targeting populations at risk of job displacement due to AGI. Focus on developing skills complementary to AGI, such as creativity, emotional intelligence, and high-level cognitive abilities.\n",
      "   - Encourage partnerships between government, industry, and educational institutions to anticipate skills needed for future jobs and adapt curricula accordingly.\n",
      "\n",
      "2. **Support for Displaced Workers:**\n",
      "   - Establish scalable support mechanisms like temporary wage subsidies and career counseling to ease workers' transition into new roles or sectors.\n",
      "   - Consider policies like UBI or transitional income support for workers significantly impacted by automation to ensure a stable income during retraining phases.\n",
      "\n",
      "### Economic Models and Fair Markets\n",
      "\n",
      "3. **Rethinking Economic Policies:**\n",
      "   - Explore new economic models that account for drastic productivity gains. This might include shifting tax bases from labor to capital or consumption, promoting wider wealth distribution.\n",
      "   - Evaluate the feasibility of implementing UBI as a long-term strategy to mitigate income inequality exacerbated by automation.\n",
      "\n",
      "4. **Promote Competition and Innovation:**\n",
      "   - Implement antitrust policies to prevent AGI monopolies and support startups and SMEs developing novel AGI technologies.\n",
      "   - Establish funding programs and incentives for innovation in AGI applications, especially those addressing public welfare and global challenges.\n",
      "\n",
      "### Ethical and Regulatory Frameworks\n",
      "\n",
      "5. **Establish Robust Governance Structures:**\n",
      "   - Develop a comprehensive legal framework addressing ethical and safety standards for AGI development and deployment.\n",
      "   - Encourage the creation of international coalitions to establish common standards and guidelines for AGI ethics, safety, and control, ensuring global alignment and reducing geopolitical risks.\n",
      "\n",
      "6. **Advance Research in Ethical AGI:**\n",
      "   - Fund research into ethical implications and value-aligned AGI, focusing on developing systems that align with human values and societal needs.\n",
      "   - Foster collaborations between tech companies, academicians, policymakers, and ethicists to create transparent and accountable AGI systems.\n",
      "\n",
      "### Social Implications and Global Accessibility\n",
      "\n",
      "7. **Promote Inclusive Access:**\n",
      "   - Implement policies to ensure AGI technologies are accessible to diverse and underserved communities, fostering inclusive economic growth.\n",
      "   - Support international development programs that facilitate AGI implementation in developing countries, ensuring equitable participation in the benefits of AGI.\n",
      "\n",
      "8. **Strengthen Social Safety Nets:**\n",
      "   - Enhance existing social safety nets to address potential economic inequalities exacerbated by AGI, including universal healthcare and childcare support to reduce societal disparities.\n",
      "\n",
      "### Global Collaboration and Ethical Standards\n",
      "\n",
      "9. **Encourage International Dialogue:**\n",
      "   - Facilitate cross-border discussions and collaborations to harmonize AGI regulations, ensuring widespread adoption of ethical practices.\n",
      "   - Lead and support global initiatives on AGI development that focus on resolving pressing global issues such as climate change, healthcare, and poverty alleviation.\n",
      "\n",
      "By implementing these strategic policy measures, governments can maximize the economic benefits of AGI while minimizing its potential disruptions and fostering a fair and equitable society. These policies aim to ensure that AGI is developed and deployed in a manner aligned with human values and the greater good.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "User received the chat history:\n",
      "Based on the economic analysis provided, here's a comprehensive set of policy recommendations to manage the implementation and development of AGI:\n",
      "\n",
      "### Workforce Transition and Development\n",
      "\n",
      "1. **Investment in Education and Training:**\n",
      "   - Implement widespread reskilling and upskilling programs targeting populations at risk of job displacement due to AGI. Focus on developing skills complementary to AGI, such as creativity, emotional intelligence, and high-level cognitive abilities.\n",
      "   - Encourage partnerships between government, industry, and educational institutions to anticipate skills needed for future jobs and adapt curricula accordingly.\n",
      "\n",
      "2. **Support for Displaced Workers:**\n",
      "   - Establish scalable support mechanisms like temporary wage subsidies and career counseling to ease workers' transition into new roles or sectors.\n",
      "   - Consider policies like UBI or transitional income support for workers significantly impacted by automation to ensure a stable income during retraining phases.\n",
      "\n",
      "### Economic Models and Fair Markets\n",
      "\n",
      "3. **Rethinking Economic Policies:**\n",
      "   - Explore new economic models that account for drastic productivity gains. This might include shifting tax bases from labor to capital or consumption, promoting wider wealth distribution.\n",
      "   - Evaluate the feasibility of implementing UBI as a long-term strategy to mitigate income inequality exacerbated by automation.\n",
      "\n",
      "4. **Promote Competition and Innovation:**\n",
      "   - Implement antitrust policies to prevent AGI monopolies and support startups and SMEs developing novel AGI technologies.\n",
      "   - Establish funding programs and incentives for innovation in AGI applications, especially those addressing public welfare and global challenges.\n",
      "\n",
      "### Ethical and Regulatory Frameworks\n",
      "\n",
      "5. **Establish Robust Governance Structures:**\n",
      "   - Develop a comprehensive legal framework addressing ethical and safety standards for AGI development and deployment.\n",
      "   - Encourage the creation of international coalitions to establish common standards and guidelines for AGI ethics, safety, and control, ensuring global alignment and reducing geopolitical risks.\n",
      "\n",
      "6. **Advance Research in Ethical AGI:**\n",
      "   - Fund research into ethical implications and value-aligned AGI, focusing on developing systems that align with human values and societal needs.\n",
      "   - Foster collaborations between tech companies, academicians, policymakers, and ethicists to create transparent and accountable AGI systems.\n",
      "\n",
      "### Social Implications and Global Accessibility\n",
      "\n",
      "7. **Promote Inclusive Access:**\n",
      "   - Implement policies to ensure AGI technologies are accessible to diverse and underserved communities, fostering inclusive economic growth.\n",
      "   - Support international development programs that facilitate AGI implementation in developing countries, ensuring equitable participation in the benefits of AGI.\n",
      "\n",
      "8. **Strengthen Social Safety Nets:**\n",
      "   - Enhance existing social safety nets to address potential economic inequalities exacerbated by AGI, including universal healthcare and childcare support to reduce societal disparities.\n",
      "\n",
      "### Global Collaboration and Ethical Standards\n",
      "\n",
      "9. **Encourage International Dialogue:**\n",
      "   - Facilitate cross-border discussions and collaborations to harmonize AGI regulations, ensuring widespread adoption of ethical practices.\n",
      "   - Lead and support global initiatives on AGI development that focus on resolving pressing global issues such as climate change, healthcare, and poverty alleviation.\n",
      "\n",
      "By implementing these strategic policy measures, governments can maximize the economic benefits of AGI while minimizing its potential disruptions and fostering a fair and equitable society. These policies aim to ensure that AGI is developed and deployed in a manner aligned with human values and the greater good.\n"
     ]
    }
   ],
   "source": [
    "runtime.start()\n",
    "\n",
    "await runtime.publish_message(\n",
    "    Message(content=\"Report about AGI\"),\n",
    "    topic_id=TopicId(researcher_agent_topic_type, source=\"default\"),\n",
    ")\n",
    "\n",
    "await runtime.stop_when_idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not queue.empty():\n",
    "    print((result := await queue.get()).value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë„êµ¬ (Tool) ì‚¬ìš©\n",
    "ì´ ì„¹ì…˜ì—ì„œëŠ” ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ë„êµ¬ ì‚¬ìš© ê¸°ëŠ¥ì„ ì‹œì—°í•©ë‹ˆë‹¤. Web Searchì™€ RAGëŠ” ì‚¬ëŒë“¤ì´ ë§¤ì¼ ì‚¬ìš©í•˜ëŠ” ì¸ê¸° ìˆëŠ” ê¸°ëŠ¥ìœ¼ë¡œ, AutoGenì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤:\n",
    "\n",
    "* Bing APIë¥¼ ì‚¬ìš©í•œ ì›¹ ê²€ìƒ‰ \n",
    "* Apify APIë¥¼ ì‚¬ìš©í•œ ì›¹ ìŠ¤í¬ë˜í•‘\n",
    "* RAGì„ í†µí•œ ì§ˆë¬¸ê³¼ ë‹µë³€\n",
    "\n",
    "ìì„¸í•œ ì •ë³´: https://microsoft.github.io/autogen/docs/tutorial/tool-use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bing APIë¥¼ ì‚¬ìš©í•œ ì›¹ ê²€ìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet \"autogen[websurfer]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config_dict = {\"config_list\": [{\"model\": \"gpt-4o\", \"api_type\": \"azure\", \"api_key\": os.environ[\"OPENAI_API_KEY\"],\"base_url\": os.environ[\"OPENAI_URL\"], \"api_version\": \"2024-02-01\"}]}\n",
    "\n",
    "# Put your Bing API key in the .env file in the same directory as this script\n",
    "BING_API_KEY = os.environ[\"BING_API_KEY\"]\n",
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"cache_seed\": 44,  # change the seed for different trials\n",
    "    \"config_list\": llm_config_dict['config_list'],\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "summarizer_llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"cache_seed\": 44,  # change the seed for different trials\n",
    "    \"config_list\": llm_config_dict['config_list'],\n",
    "    \"temperature\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.contrib.web_surfer import WebSurferAgent\n",
    "from autogen.agentchat import UserProxyAgent\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    \"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    "    default_auto_reply=\"\",\n",
    "    is_termination_msg=lambda x: True,\n",
    ")\n",
    "\n",
    "web_surfer = WebSurferAgent(\n",
    "    \"web_surfer\",\n",
    "    llm_config=llm_config,\n",
    "    summarizer_llm_config=summarizer_llm_config,\n",
    "    browser_config={\"viewport_size\": 4096, \"bing_api_key\": BING_API_KEY},\n",
    ")\n",
    "\n",
    "def web_surfer_tool (query: str) -> str:\n",
    "    result = user_proxy.initiate_chat(web_surfer, message=query, max_turns=1)\n",
    "    return result\n",
    "\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"You are a helpful assistant. You can call tools to help user.\",\n",
    "    model_client=model_client,\n",
    "    tools=[web_surfer_tool],\n",
    "    reflect_on_tool_use=True, # Set to True to have the model reflect on the tool use, set to False to return the tool call result directly.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: ìµœì‹  ì—ì´ì „íŠ¸ ê¸°ìˆ ì— ëŒ€í•œ ì •ë³´ë¥¼ ìš”ì•½í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. **AI ì—ì´ì „íŠ¸ (Agentic AI):** 2025ë…„ì˜ ì£¼ìš” ê¸°ìˆ  íŠ¸ë Œë“œ ì¤‘ í•˜ë‚˜ë¡œ, ì¸ê³µì§€ëŠ¥(AI) ì—ì´ì „íŠ¸ê°€ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ê¸°ì¡´ì˜ AIê°€ ì¸ê°„ì˜ ëª…ë ¹ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì—ì„œ ë” ë‚˜ì•„ê°€ ììœ¨ì ìœ¼ë¡œ ëª©í‘œë¥¼ ì„¤ì •í•˜ê³  ë¬¸ì œë¥¼ í•´ê²°í•˜ë©° í•™ìŠµê¹Œì§€ ì§„í–‰í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ AI ì—ì´ì „íŠ¸ëŠ” ë‹¤ì–‘í•œ ì‚°ì—…ì—ì„œ í˜ì‹ ê³¼ íš¨ìœ¨ì ì¸ ë¬¸ì œ í•´ê²°ì„ ê°€ì ¸ì˜¤ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ê°€íŠ¸ë„ˆ(Gartner) ë³´ê³ ì„œ:** ê°€íŠ¸ë„ˆëŠ” AI ì—ì´ì „íŠ¸ë¥¼ ë¯¸ë˜ ì „ëµ ê¸°ìˆ  íŠ¸ë Œë“œì˜ ì¼í™˜ìœ¼ë¡œ ê¼½ì•˜ìŠµë‹ˆë‹¤. ì´ëŠ” ì£¼ë¡œ ììœ¨ì ì¸ ì˜ì‚¬ê²°ì •ê³¼ ë³µì¡í•œ ì‘ì—… ìˆ˜í–‰ ëŠ¥ë ¥ì„ ê°•ì¡°í•˜ë©°, AI ê±°ë²„ë„ŒìŠ¤ í”Œë«í¼ê³¼ ê°™ì€ ê´€ë ¨ ì •ì±… ê¸°ìˆ ë„ í•¨ê»˜ ë°œì „í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì‚°ì—… ì‘ìš© ì‚¬ë¡€:** AI ì—ì´ì „íŠ¸ëŠ” ì œì¡°, ê¸ˆìœµ, ì˜ë£Œ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ê³  ìˆìœ¼ë©°, ê¸°ì—…ë“¤ì—ê²Œ í˜ì‹ ì ì¸ ë³€í™”ì™€ ê²½ìŸë ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ê¸°ìˆ ì  ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì–´ì‹œìŠ¤í„´íŠ¸ AIë‚˜ ê´‘ê³  ì†”ë£¨ì…˜ ë“±ìœ¼ë¡œ êµ¬ì²´ì ì¸ ì‘ìš©ì´ ì´ë£¨ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ê¸°ìˆ ì€ ì•ìœ¼ë¡œ ë” ë°œì „í•˜ë©°, ì¸ê°„ê³¼ ê¸°ê³„ê°€ í˜‘ë ¥í•˜ëŠ” ë°©ì‹ì— í° ë³€í™”ë¥¼ ê°€ì ¸ì˜¬ ê²ƒì…ë‹ˆë‹¤. AI ì—ì´ì „íŠ¸ëŠ” ë‹¨ìˆœí•œ ë„êµ¬ë¥¼ ë„˜ì–´, ëŠ¥ë™ì ìœ¼ë¡œ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦¬ëŠ” ì‹œìŠ¤í…œìœ¼ë¡œì„œì˜ ì—­í• ì„ ê°•í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê° ì‚°ì—…ì—ì„œ ì´ ê¸°ìˆ ì„ ì–´ë–»ê²Œ í™œìš©í•  ê²ƒì¸ì§€ì— ëŒ€í•œ ì „ëµì´ ì¤‘ìš”í•œ ì£¼ì œë¡œ ë– ì˜¤ë¥´ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# What is Artificial General Intelligence ?\n",
    "\n",
    "task1 = \"\"\"\n",
    "ìµœì‹  ì—ì´ì „íŠ¸ ê¸°ìˆ ì„ ì•Œì•„ë³´ê³  ì‹¶ì–´ìš”.\n",
    "\"\"\"\n",
    "\n",
    "# user_proxy.initiate_chat(web_surfer, message=task1, max_turns=1)\n",
    "\n",
    "response = await assistant.on_messages([TextMessage(content=task1, source=\"user\")], CancellationToken())\n",
    "print(\"Assistant:\", response.chat_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: ê¸°ì‚¬ì˜ ì œëª©ì€ \"ê°€íŠ¸ë„ˆ, 2025ë…„ 10ëŒ€ ê¸°ìˆ  íŠ¸ë Œë“œ ì¤‘ 9ê°œê°€ AI...ì—ì´ì „íŠ¸Â·ê³µê°„ì§€ëŠ¥ ë“± ì„ ì •\"ì…ë‹ˆë‹¤. í•´ë‹¹ ì•„í‹°í´ì—ì„œëŠ” ê°€íŠ¸ë„ˆê°€ ë°œí‘œí•œ 2025ë…„ 10ëŒ€ ê¸°ìˆ  íŠ¸ë Œë“œ ì¤‘ 9ê°œê°€ AI ê´€ë ¨ ê¸°ìˆ ì„ì„ ê°•ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤. AI ì—ì´ì „íŠ¸ì™€ ê³µê°„ì§€ëŠ¥ ë“±ì´ ì£¼ìš” íŠ¸ë Œë“œë¡œ ê¼½í˜”ìœ¼ë©°, ì´ëŸ¬í•œ ê¸°ìˆ ë“¤ì´ ë¯¸ë˜ì˜ ê¸°ìˆ  ë°œì „ì— ìˆì–´ì„œì˜ ì¤‘ìš”í•œ ì—­í• ì„ í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.\n",
      "\n",
      "ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "task2 = \"Click on the first link.\"\n",
    "# user_proxy.initiate_chat(web_surfer, message=task2)\n",
    "\n",
    "response = await assistant.on_messages([TextMessage(content=task2, source=\"user\")], CancellationToken())\n",
    "print(\"Assistant:\", response.chat_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Artificial General Intelligence (AGI) and classical (or narrow/specialized) AI serve different purposes and have distinct characteristics:\n",
      "\n",
      "1. **Scope of Capability:**\n",
      "   - **AGI (Artificial General Intelligence):** AGI refers to a type of AI that possesses the ability to understand, learn, and apply intelligence across a wide range of tasks, similar to human cognitive abilities. AGI would be capable of performing any intellectual task that a human can do.\n",
      "   - **Classic AI (Narrow AI):** In contrast, classical AI, also known as narrow or specialized AI, is designed to perform a specific task or a set of tasks very well. These tasks are highly focused, such as image recognition, language translation, or even playing chess.\n",
      "\n",
      "2. **Flexibility:**\n",
      "   - **AGI:** Designed to be flexible and adaptable, AGI can transfer its learning from one domain to another and apply knowledge in varied contexts.\n",
      "   - **Classic AI:** Lacks versatility and is constrained to pre-defined parameters. Classic AI cannot easily transfer its capabilities to different tasks outside its original design or programming.\n",
      "\n",
      "3. **Learning Ability:**\n",
      "   - **AGI:** Would require the ability to learn and improve its performance continuously, much like a human, from a broader set of inputs and experiences.\n",
      "   - **Classic AI:** Typically improves its performance by leveraging data specific to its domain through techniques like machine learning, but it lacks the extensive adaptive learning capabilities of AGI.\n",
      "\n",
      "4. **Developmental State:**\n",
      "   - **AGI:** Still largely theoretical and remains a goal for future research. Creating AGI involves solving complex and unsolved problems in AI research about cognition, generalized learning, and common sense.\n",
      "   - **Classic AI:** Has been successfully implemented in various applications and is widely used in industry today.\n",
      "\n",
      "In summary, while classical AI specializes in specific tasks, AGI encompasses a broader and more human-like understanding and processing capacity. However, AGI is not yet realized and remains a hot topic for exploration in the AI field.\n"
     ]
    }
   ],
   "source": [
    "task3 = \"What is the difference beween AGI and classic AI?\"\n",
    "# user_proxy.initiate_chat(web_surfer, message=task3)\n",
    "\n",
    "response = await assistant.on_messages([TextMessage(content=task3, source=\"user\")], CancellationToken())\n",
    "print(\"Assistant:\", response.chat_message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apify APIë¥¼ ì‚¬ìš©í•œ ì›¹ ìŠ¤í¬ë˜í•‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your Apify API key in the .env file in the same directory as this script\n",
    "APIFY_API_KEY = os.environ[\"APIFY_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apify_client import ApifyClient\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "def scrape_page(url: Annotated[str, \"The URL of the web page to scrape\"]) -> Annotated[str, \"Scraped content\"]:\n",
    "    # Initialize the ApifyClient with your API token\n",
    "    client = ApifyClient(token=APIFY_API_KEY)\n",
    "\n",
    "    # Prepare the Actor input\n",
    "    run_input = {\n",
    "        \"startUrls\": [{\"url\": url}],\n",
    "        \"useSitemaps\": False,\n",
    "        \"crawlerType\": \"playwright:firefox\",\n",
    "        \"includeUrlGlobs\": [],\n",
    "        \"excludeUrlGlobs\": [],\n",
    "        \"ignoreCanonicalUrl\": False,\n",
    "        \"maxCrawlDepth\": 0,\n",
    "        \"maxCrawlPages\": 1,\n",
    "        \"initialConcurrency\": 0,\n",
    "        \"maxConcurrency\": 200,\n",
    "        \"initialCookies\": [],\n",
    "        \"proxyConfiguration\": {\"useApifyProxy\": True},\n",
    "        \"maxSessionRotations\": 10,\n",
    "        \"maxRequestRetries\": 5,\n",
    "        \"requestTimeoutSecs\": 60,\n",
    "        \"dynamicContentWaitSecs\": 10,\n",
    "        \"maxScrollHeightPixels\": 5000,\n",
    "        \"removeElementsCssSelector\": \"\"\"nav, footer, script, style, noscript, svg,\n",
    "    [role=\\\"alert\\\"],\n",
    "    [role=\\\"banner\\\"],\n",
    "    [role=\\\"dialog\\\"],\n",
    "    [role=\\\"alertdialog\\\"],\n",
    "    [role=\\\"region\\\"][aria-label*=\\\"skip\\\" i],\n",
    "    [aria-modal=\\\"true\\\"]\"\"\",\n",
    "        \"removeCookieWarnings\": True,\n",
    "        \"clickElementsCssSelector\": '[aria-expanded=\"false\"]',\n",
    "        \"htmlTransformer\": \"readableText\",\n",
    "        \"readableTextCharThreshold\": 100,\n",
    "        \"aggressivePrune\": False,\n",
    "        \"debugMode\": True,\n",
    "        \"debugLog\": True,\n",
    "        \"saveHtml\": True,\n",
    "        \"saveMarkdown\": True,\n",
    "        \"saveFiles\": False,\n",
    "        \"saveScreenshots\": False,\n",
    "        \"maxResults\": 9999999,\n",
    "        \"clientSideMinChangePercentage\": 15,\n",
    "        \"renderingTypeDetectionPercentage\": 10,\n",
    "    }\n",
    "\n",
    "    # Run the Actor and wait for it to finish\n",
    "    run = client.actor(\"aYG0l9s7dbB7j3gbS\").call(run_input=run_input)\n",
    "\n",
    "    # Fetch and print Actor results from the run's dataset (if there are any)\n",
    "    text_data = \"\"\n",
    "    for item in client.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
    "        text_data += item.get(\"text\", \"\") + \"\\n\"\n",
    "\n",
    "    average_token = 0.75\n",
    "    max_tokens = 20000  # slightly less than max to be safe 32k\n",
    "    text_data = text_data[: int(average_token * max_tokens)]\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The \"Intelligent Agent\" Wikipedia page provides a comprehensive overview of intelligent agents in the context of artificial intelligence (AI). Here's a summary of key aspects covered:\n",
      "\n",
      "1. **Definition**: An intelligent agent perceives its environment, takes actions autonomously to achieve goals, and can improve its performance through machine learning or acquiring knowledge.\n",
      "\n",
      "2. **Types**: Intelligent agents can range from simple to complex, such as thermostats to autonomous systems like self-driving cars.\n",
      "\n",
      "3. **Objective Function**: Intelligent agents operate based on an objective function or goal function, guiding their actions to optimize certain outcomes, such as maximizing rewards in reinforcement learning.\n",
      "\n",
      "4. **Relationship to Other Disciplines**: They relate to agents in economics and are studied within cognitive science, ethics, and the philosophy of practical reason.\n",
      "\n",
      "5. **Rational Agents**: Agents strive to achieve the best possible outcome based on their knowledge and experiences using a rational approach.\n",
      "\n",
      "6. **Utility and Performance Measures**: They use various functions like utility, reward, fitness, and loss functions to measure performance and guide learning.\n",
      "\n",
      "7. **Agent Functions**: An intelligent agent's behavior is determined by an agent function, which maps perceptual history to actions. \n",
      "\n",
      "8. **Classes of Agents**: Russell & Norvig classify agents into simple reflex, model-based reflex, goal-based, utility-based, and learning agents. \n",
      "\n",
      "9. **Theories and Classifications**: Includes Russell & Norvig's, and Weiss's classifications of agents, highlighting different decision-making approaches like logic-based, reactive, beliefâ€“desireâ€“intention (BDI), and layered architectures.\n",
      "\n",
      "10. **Interdisciplinary Communication**: Intelligent agent concepts help bridge AI with fields like optimization and economics.\n",
      "\n",
      "The page also discusses specific models like evolutionary algorithms, generative adversarial networks, and frameworks for creating rational agents in AI.\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent, register_function\n",
    "\n",
    "scrape_assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"You are a web scrapper and you can scrape any web page using the tools provided.\",\n",
    "    model_client=model_client,\n",
    "    tools=[scrape_page],\n",
    "    reflect_on_tool_use=True, # Set to True to have the model reflect on the tool use, set to False to return the tool call result directly.\n",
    ")\n",
    "\n",
    "# url = 'https://en.wikipedia.org/wiki/Artificial_general_intelligence'\n",
    "url = 'https://en.wikipedia.org/wiki/Intelligent_agent'\n",
    "\n",
    "scrape_task=f\"Can you scrape {url} for me?\"\n",
    "response = await scrape_assistant.on_messages([TextMessage(content=scrape_task, source=\"user\")], CancellationToken())\n",
    "print(\"Assistant:\", response.chat_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"agi_wiki_content.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(response.chat_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ìŠ¤í¬ë©í•œ ìœ„í‚¤ íŒŒì¼ì— ëŒ€í•´ RAGì„ ìˆ˜í–‰ (Autogen 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in ./.venv/lib/python3.13/site-packages (0.6.3)\n",
      "Requirement already satisfied: build>=1.0.3 in ./.venv/lib/python3.13/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in ./.venv/lib/python3.13/site-packages (from chromadb) (2.10.6)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in ./.venv/lib/python3.13/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in ./.venv/lib/python3.13/site-packages (from chromadb) (0.115.8)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in ./.venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in ./.venv/lib/python3.13/site-packages (from chromadb) (2.2.3)\n",
      "Requirement already satisfied: posthog>=2.4.0 in ./.venv/lib/python3.13/site-packages (from chromadb) (3.13.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./.venv/lib/python3.13/site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./.venv/lib/python3.13/site-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./.venv/lib/python3.13/site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./.venv/lib/python3.13/site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in ./.venv/lib/python3.13/site-packages (from chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./.venv/lib/python3.13/site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./.venv/lib/python3.13/site-packages (from chromadb) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./.venv/lib/python3.13/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./.venv/lib/python3.13/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./.venv/lib/python3.13/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in ./.venv/lib/python3.13/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./.venv/lib/python3.13/site-packages (from chromadb) (1.70.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./.venv/lib/python3.13/site-packages (from chromadb) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./.venv/lib/python3.13/site-packages (from chromadb) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./.venv/lib/python3.13/site-packages (from chromadb) (32.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in ./.venv/lib/python3.13/site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in ./.venv/lib/python3.13/site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./.venv/lib/python3.13/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./.venv/lib/python3.13/site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./.venv/lib/python3.13/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.13/site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: packaging>=19.1 in ./.venv/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in ./.venv/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in ./.venv/lib/python3.13/site-packages (from fastapi>=0.95.2->chromadb) (0.45.3)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (4.8.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./.venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./.venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./.venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in ./.venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in ./.venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in ./.venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in ./.venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in ./.venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./.venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./.venv/lib/python3.13/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./.venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.67.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.30.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.51b0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in ./.venv/lib/python3.13/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./.venv/lib/python3.13/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./.venv/lib/python3.13/site-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./.venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./.venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./.venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./.venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in ./.venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.13/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.13/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.13/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./.venv/lib/python3.13/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from sentence_transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence_transformers)\n",
      "  Downloading torch-2.6.0-cp313-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Downloading scipy-1.15.1-cp313-cp313-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.13/site-packages (from sentence_transformers) (0.28.1)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.13/site-packages (from sentence_transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
      "Collecting networkx (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached setuptools-75.8.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence_transformers)\n",
      "  Downloading MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.1.31)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Downloading torch-2.6.0-cp313-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp313-cp313-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.1-cp313-cp313-macosx_14_0_arm64.whl (24.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading safetensors-0.5.2-cp38-abi3-macosx_11_0_arm64.whl (408 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached setuptools-75.8.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Installing collected packages: threadpoolctl, sympy, setuptools, scipy, safetensors, networkx, MarkupSafe, joblib, scikit-learn, jinja2, torch, transformers, sentence_transformers\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "Successfully installed MarkupSafe-3.0.2 jinja2-3.1.5 joblib-1.4.2 networkx-3.4.2 safetensors-0.5.2 scikit-learn-1.6.1 scipy-1.15.1 sentence_transformers-3.4.1 setuptools-75.8.0 sympy-1.13.1 threadpoolctl-3.5.0 torch-2.6.0 transformers-4.48.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chromadb\n",
    "%pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen import AssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "import chromadb\n",
    "\n",
    "DOC_PATH = [\"./agi_wiki_content.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {'config_list': llm_config_dict['config_list'], 'timeout': 60, 'cache_seed': 88, 'temperature': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chromadb.api.client.Client at 0x10f4f63c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chromadb.PersistentClient(path=\"/tmp/chromadb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    llm_config=llm_config\n",
    ")\n",
    "        \n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    retrieve_config={\n",
    "        \"task\": \"qa\",\n",
    "        \"docs_path\": DOC_PATH,\n",
    "        \"chunk_token_size\": 1000,\n",
    "        \"model\": llm_config_dict[\"config_list\"][0][\"model\"],\n",
    "        \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
    "        \"collection_name\": \"boise_idaho\",\n",
    "        \"get_or_create\": False, # if True, will create/return a collection for the retrieve chat.\n",
    "    },\n",
    "    code_execution_config={\"use_docker\": False}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to create collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 02:03:25,095 - autogen.agentchat.contrib.retrieve_user_proxy_agent - INFO - Found 1 chunks.\u001b[0m\n",
      "2025-02-17 02:03:25,099 - autogen.agentchat.contrib.vectordb.chromadb - INFO - No content embedding is provided. Will use the VectorDB's embedding function to generate the content embedding.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorDB returns doc_ids:  [['51484f60']]\n",
      "\u001b[32mAdding content of doc 51484f60 to context.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# prompt = \"What is the difference beween AGI and classic AI\"\n",
    "prompt = \"What is Intelligent Agent?\"\n",
    "res = ragproxyagent.initiate_chat(assistant, message=ragproxyagent.message_generator, problem=prompt, n_results=1, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:What is Intelligent Agent?\n",
      "Answer from RAG: An intelligent agent is an entity that perceives its environment, takes actions autonomously to achieve goals, and can improve its performance through learning or acquiring knowledge.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question:{prompt}\")\n",
    "print(f\"Answer from RAG: {res.chat_history[-1]['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Chat \n",
    "\n",
    "ì§€ê¸ˆê¹Œì§€ ë‘ ì—ì´ì „íŠ¸ ë˜ëŠ” ë‘ ì—ì´ì „íŠ¸ ê°„ì˜ ì¼ë ¨ì˜ ìƒí˜¸ì‘ìš©ì„ í¬í•¨í•˜ëŠ” ëŒ€í™” íŒ¨í„´ì„ ì•Œì•„ë´¤ìŠµë‹ˆë‹¤.\n",
    "\n",
    "AutoGenì€ ê·¸ë£¹ ì±„íŒ…(**group chat**)ì´ë¼ëŠ” ë” ê´‘ë²”ìœ„í•œ ëŒ€í™” ëª¨ë¸ì„ ì†Œê°œí•˜ë©°, ì´ ëª¨ë¸ì€ ë‘ ê°œ ì´ìƒì˜ ì—ì´ì „íŠ¸ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ë£¹ ì±„íŒ…ì˜ ê¸°ë³¸ ê°œë…ì€ ëª¨ë“  ì—ì´ì „íŠ¸ê°€ í•˜ë‚˜ì˜ í†µí•©ëœ ëŒ€í™” ìŠ¤ë ˆë“œì— ì°¸ì—¬í•˜ê³  ë™ì¼í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³µìœ í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ì ‘ê·¼ ë°©ì‹ì€ ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ê°„ì˜ í˜‘ë ¥ì´ í•„ìš”í•œ ì‘ì—…ì— ìœ ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"./images/autogen_image3.png\" alt=\"GroupChat Flow\" width=\"500\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ë£¹ ì±„íŒ… ê´€ë¦¬ì(Group Chat Manager)ëŠ” ë‹¤ìŒ ë‹¨ê³„ë¥¼ í†µí•´ ê·¸ë£¹ ì±„íŒ…ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "1.\tê·¸ë£¹ ì±„íŒ… ê´€ë¦¬ì(Group Chat Manager)ê°€ ë°œì–¸í•  ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\n",
    "2.\tì„ íƒëœ ì—ì´ì „íŠ¸ê°€ ë°œì–¸í•˜ê³ , ë©”ì‹œì§€ê°€ ê·¸ë£¹ ì±„íŒ… ê´€ë¦¬ìì—ê²Œ ë‹¤ì‹œ ì „ì†¡ë©ë‹ˆë‹¤.\n",
    "3.\tê·¸ë£¹ ì±„íŒ… ê´€ë¦¬ìê°€ ë©”ì‹œì§€ë¥¼ ê·¸ë£¹ ë‚´ ë‹¤ë¥¸ ëª¨ë“  ì—ì´ì „íŠ¸ì—ê²Œ ì „íŒŒí•©ë‹ˆë‹¤.\n",
    "4.\tì´ ê³¼ì •ì€ ëŒ€í™”ê°€ ì¤‘ë‹¨ë  ë•Œê¹Œì§€ ë°˜ë³µë©ë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ë£¹ ì±„íŒ… ê´€ë¦¬ì(Group Chat Manager)ëŠ” ì—¬ëŸ¬ ì „ëµì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒ\n",
    "\n",
    "- **round_robin**:  ê·¸ë£¹ ì±„íŒ… ê´€ë¦¬ìê°€ ì œê³µëœ ì—ì´ì „íŠ¸ì˜ ìˆœì„œì— ë”°ë¼ ë¼ìš´ë“œ ë¡œë¹ˆ ë°©ì‹ìœ¼ë¡œ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒ\n",
    "- **random**:  ê·¸ë£¹ ì±„íŒ… ê´€ë¦¬ìê°€ ì—ì´ì „íŠ¸ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ íƒ\n",
    "- **manual**:  ê·¸ë£¹ ì±„íŒ… ê´€ë¦¬ìê°€ ì‚¬ëŒì˜ ì…ë ¥ì„ ìš”ì²­í•˜ì—¬ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒ\n",
    "- **auto**:  Default ì „ëµìœ¼ë¡œ, ê·¸ë£¹ ì±„íŒ… ê´€ë¦¬ìì˜ LLM (ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)ì„ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## SelectorGroupChat ê°œìš”\n",
    "\n",
    "SelectorGroupChatì€ íŒ€ ë‚´ì—ì„œ ì°¸ê°€ìë“¤ì´ ë¸Œë¡œë“œìºìŠ¤íŒ…ëœ ë©”ì‹œì§€ë¥¼ ë²ˆê°ˆì•„ ì²˜ë¦¬í•˜ëŠ” êµ¬ì¡°ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤. ê³µìœ ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì´ ë‹¤ìŒ ë°œì–¸ìë¥¼ ì„ íƒí•˜ì—¬ ë™ì ì´ê³  ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ì˜ í˜‘ì—…ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì£¼ìš” ê¸°ëŠ¥\n",
    "\tâ€¢\tëª¨ë¸ ê¸°ë°˜ ë°œì–¸ì ì„ íƒ: ìƒì„± ëª¨ë¸ì´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë°œì–¸ìë¥¼ ìë™ìœ¼ë¡œ ê²°ì •\n",
    "\tâ€¢\tì°¸ê°€ì ì—­í•  ë° ì„¤ëª… êµ¬ì„± ê°€ëŠ¥: ê° ì°¸ê°€ìì˜ ì—­í• ê³¼ ì„¤ëª…ì„ ì„¤ì •í•˜ì—¬ íŒ€ ë‚´ í˜‘ì—… ë°©ì‹ì„ ë§ì¶¤í™”\n",
    "\tâ€¢\të™ì¼ ë°œì–¸ìì˜ ì—°ì† ë°œì–¸ ë°©ì§€ (ì„ íƒì  ê¸°ëŠ¥): ë™ì¼í•œ ì‚¬ìš©ìê°€ ì—°ì†ìœ¼ë¡œ ë°œì–¸í•˜ì§€ ì•Šë„ë¡ ì œí•œ ê°€ëŠ¥\n",
    "\tâ€¢\të§ì¶¤í˜• ì„ íƒ í”„ë¡¬í”„íŠ¸(Customizable Selection Prompting) ì„¤ì • ê°€ëŠ¥: ë°œì–¸ì ì„ íƒì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©ì ì •ì˜ ê°€ëŠ¥\n",
    "\tâ€¢\tì„ íƒ í•¨ìˆ˜ ì¬ì •ì˜: ê¸°ë³¸ ëª¨ë¸ ê¸°ë°˜ ì„ íƒì„ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬, ë§ì¶¤í˜• ì„ íƒ ë¡œì§ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agents ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "from typing import Annotated\n",
    "import datetime\n",
    "\n",
    "def save_report(report: str) -> str:\n",
    "    try:\n",
    "        file_name = \"report_\"+str(datetime.datetime.now().strftime(\"%Y%m%d_%H:%M:%S\"))+ \".md\"\n",
    "        with open(file_name, \"w\") as f:\n",
    "            f.write(report)\n",
    "        return \"Report saved successfully.\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"Failed to save the report.\"\n",
    "\n",
    "def browse_web(query: str) -> str:\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            results = [r for r in ddgs.text(query, max_results=1)]\n",
    "            return results if results else \"Not Found\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def web_search_tool (query: Annotated [str, 'Query string containing information that you want to search using the internet']) -> str:\n",
    "    result=browse_web(query)\n",
    "    return result\n",
    "\n",
    "def save_report_tool(report: Annotated[str, 'Report in markdown format']) -> str:\n",
    "    result=save_report(report)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "planner = AssistantAgent(\n",
    "    \"PlanningAgent\",\n",
    "    description=\"An agent for planning tasks, this agent should be the first to engage when given a new task.\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"\"\"\n",
    "    You are a planning agent.\n",
    "    Your job is to break down complex tasks into smaller, manageable subtasks.\n",
    "    Your team members are:\n",
    "        Economist\n",
    "        WhiteCollarWorker\n",
    "        Environmentalist\n",
    "        ReportAgent\n",
    "\n",
    "    You only plan and delegate tasks - you do not execute them yourself.\n",
    "\n",
    "    When assigning tasks, use this format:\n",
    "    1. <agent> : <task>\n",
    "\n",
    "    After all tasks are complete, summarize the findings and end with \"TERMINATE\".\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "reportagent = AssistantAgent(\n",
    "    \"ReportAgent\",\n",
    "    description=\"Responsible for creating a report by extracting insights from the chat history.\",\n",
    "    model_client=model_client,\n",
    "    tools=[save_report_tool],\n",
    "    reflect_on_tool_use=True, # Set to True to have the model reflect on the tool use, set to False to return the tool call result directly.\n",
    "    system_message=\"\"\"Once plan is approved, \n",
    "                    You are responsible for creating a report by extracting insights from the other agents. \n",
    "                    Save and return report in well formatted markdown format, save the report and TERMINATE.\"\"\",\n",
    ")\n",
    "\n",
    "economist = AssistantAgent(\n",
    "    \"Economist\",\n",
    "    description=\"Expert in global economics and the impact of conflicts.\",\n",
    "    model_client=model_client,\n",
    "    tools=[web_search_tool],\n",
    "    reflect_on_tool_use=True, # Set to True to have the model reflect on the tool use, set to False to return the tool call result directly.\n",
    "    system_message=\"\"\"You are a highly experienced economist specializing in global economic trends and geopolitical risks. \n",
    "                    You are responsible for addressing part of the plan assigned by the Planner.\"\"\",\n",
    ")\n",
    "\n",
    "whitecollarworker = AssistantAgent(\n",
    "    \"WhiteCollarWorker\",\n",
    "    description=\"Highly experienced white collar worker with a pragmatic approach to sustain healthy economy and environment.\",\n",
    "    model_client=model_client,\n",
    "    tools=[web_search_tool],\n",
    "    reflect_on_tool_use=True, # Set to True to have the model reflect on the tool use, set to False to return the tool call result directly.\n",
    "    system_message=\"\"\"You are an average white collar worker concerned about the economy and the environment. \n",
    "                    You are responsible for addressing part of the plan assigned by the Planner.\"\"\",\n",
    ")\n",
    "\n",
    "environmentalist = AssistantAgent(\n",
    "    \"Environmentalist\",\n",
    "    description=\"Promotes environmental awareness and sustainable solutions.\",\n",
    "    model_client=model_client,\n",
    "    tools=[web_search_tool],\n",
    "    reflect_on_tool_use=True, # Set to True to have the model reflect on the tool use, set to False to return the tool call result directly.\n",
    "    system_message=\"\"\"You are an environmentalist advocating for sustainable practices and conservation of natural resources. \n",
    "                    You are responsible for addressing part of the plan assigned by the Planner.\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/autogen_image4.png\" alt=\"GroupChat Flow\" width=\"900\" style=\"display: block; margin-left: auto; margin-right: auto; background-color: white;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ë„êµ¬ë¡œ Agent ê¸°ëŠ¥ ê°•í™”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/autogen_image5.png\" alt=\"GroupChat Flow\" width=\"900\" style=\"display: block; margin-left: auto; margin-right: auto; background-color: white;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Chat Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/autogen_image6.png\" alt=\"GroupChat Flow\" width=\"900\" style=\"display: block; margin-left: auto; margin-right: auto; background-color: white;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autogen v0.4\n",
    "\n",
    "from typing import Sequence\n",
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "from autogen_agentchat.messages import AgentEvent, ChatMessage\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "text_mention_termination = TextMentionTermination(\"TERMINATE\")\n",
    "max_messages_termination = MaxMessageTermination(max_messages=10)\n",
    "termination = text_mention_termination | max_messages_termination\n",
    "\n",
    "selector_prompt = \"\"\"Select an agent to perform task.\n",
    "\n",
    "{roles}\n",
    "\n",
    "Current conversation context:\n",
    "{history}\n",
    "\n",
    "Read the above conversation, then select an agent from {participants} to perform the next task.\n",
    "Make sure the planner agent has assigned tasks before other agents start working.\n",
    "Only select one agent.\n",
    "\"\"\"\n",
    "\n",
    "user_proxy_agent = UserProxyAgent(\"UserProxyAgent\", description=\"A proxy for the user to approve or disapprove tasks.\")\n",
    "\n",
    "\n",
    "def selector_func_with_user_proxy(messages: Sequence[AgentEvent | ChatMessage]) -> str | None:\n",
    "    if messages[-1].source != planner.name and messages[-1].source != user_proxy_agent.name:\n",
    "        # Planning agent should be the first to engage when given a new task, or check progress.\n",
    "        return planner.name\n",
    "    if messages[-1].source == planner.name:\n",
    "        if messages[-2].source == user_proxy_agent.name and \"APPROVE\" in messages[-1].content.upper():  # type: ignore\n",
    "            # User has approved the plan, proceed to the next agent.\n",
    "            return None\n",
    "        # Use the user proxy agent to get the user's approval to proceed.\n",
    "        return user_proxy_agent.name\n",
    "    if messages[-1].source == user_proxy_agent.name:\n",
    "        # If the user does not approve, return to the planning agent.\n",
    "        if \"APPROVE\" not in messages[-1].content.upper():  # type: ignore\n",
    "            return planner.name\n",
    "    return None\n",
    "\n",
    "\n",
    "team = SelectorGroupChat(\n",
    "    [planner, economist, whitecollarworker, environmentalist, reportagent],\n",
    "    model_client=model_client,\n",
    "    termination_condition=termination,\n",
    "    selector_prompt=selector_prompt,\n",
    "    # selector_func=selector_func_with_user_proxy,\n",
    "    allow_repeated_speaker=True, # Allow an agent to speak multiple turns in a row.\n",
    ")\n",
    "\n",
    "# await Console(team.run_stream(task=\"Create a report on : Analyzing the potential global ramifications of onset of Artificial general intelligence.\"))\n",
    "\n",
    "# await Console(team.run_stream(task=\"â€œì¸ê³µì§€ëŠ¥ ì¼ë°˜í™”(AGI)ì˜ ì¶œí˜„ì´ ì´ˆë˜í•  ìˆ˜ ìˆëŠ” ê¸€ë¡œë²Œ ì˜í–¥ ë¶„ì„â€ì— ëŒ€í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "ìµœê·¼ SKí…”ë ˆì½¤ì´ ì§‘ì¤‘í•˜ê³  ìˆëŠ” AI ë°ì´í„°ì„¼í„°ì˜ ê¸€ë¡œë²Œ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥ ë¶„ì„â€ì— ëŒ€í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
      "---------- PlanningAgent ----------\n",
      "To create a comprehensive report on the \"Global Business Impact Analysis of AI Data Centers that SK Telecom is Focusing on Recently,\" we need to break down the task into several subtasks, engaging the appropriate team members to address different aspects of the report.\n",
      "\n",
      "1. Economist: Analyze the economic implications of AI data centers on a global scale, including market trends, potential growth opportunities, and economic benefits for SK Telecom.\n",
      "2. WhiteCollarWorker: Research SK Telecom's strategies and investments in AI data centers, including partnerships, expansion plans, and integration into their existing business model.\n",
      "3. Environmentalist: Examine the environmental impact of AI data centers, highlighting both the challenges and the positive contributions that SK Telecom might be making with sustainable practices.\n",
      "4. ReportAgent: Compile the information and analysis provided by the Economist, WhiteCollarWorker, and Environmentalist into a cohesive report, ensuring all sections are clearly presented and conclusions are well-supported.\n",
      "\n",
      "Please proceed with each task and provide your findings.\n",
      "---------- Economist ----------\n",
      "[FunctionCall(id='call_6PGN1VPNbJfLExFz46XCvWj5', arguments='{\"query\":\"global economic impact of AI data centers\"}', name='web_search_tool')]\n",
      "---------- Economist ----------\n",
      "[FunctionExecutionResult(content=\"[{'title': 'AI to drive 165% increase in data center power demand by 2030', 'href': 'https://www.goldmansachs.com/insights/articles/ai-to-drive-165-increase-in-data-center-power-demand-by-2030', 'body': 'The explosion in interest in generative artificial intelligence has resulted in an arms race to develop the technology, which will require many high-density data centers as well as much more electricity to power them.. Goldman Sachs Research forecasts global power demand from data centers will increase 50% by 2027 and by as much as 165% by the end of the decade (compared with 2023), writes ...'}]\", call_id='call_6PGN1VPNbJfLExFz46XCvWj5', is_error=False)]\n",
      "---------- Economist ----------\n",
      "### Global Economic Impact Analysis of AI Data Centers\n",
      "\n",
      "1. **Market Trends and Growth Opportunities**:\n",
      "    - The rise of artificial intelligence (AI) is driving a significant increase in the demand for data centers globally. This trend is expected to continue, with power demand from data centers anticipated to increase by 50% by 2027 and up to 165% by 2030. This reflects a substantial growth opportunity for companies like SK Telecom involved in the AI data center segment.\n",
      "    \n",
      "2. **Economic Benefits**:\n",
      "    - **Job Creation**: As SK Telecom expands its AI data centers, it will likely contribute to job creation in both the technology and construction sectors, as well as ongoing operational roles.\n",
      "    - **Innovation and Competitiveness**: The presence of advanced AI data centers will position SK Telecom as a leader in digital services and technologies, enhancing its competitiveness in the global market.\n",
      "    - **Investment and Revenue Generation**: Investments in AI infrastructure are likely to attract further domestic and international investments, leading to an increase in revenue streams both directly (through data services) and indirectly (by supporting the AI ecosystem development).\n",
      "\n",
      "3. **Potential Risks and Considerations**:\n",
      "    - **Energy Consumption**: As the demand for AI capabilities grows, so does the energy required to power these data centers. Companies must balance growth with sustainable practices.\n",
      "    - **Geopolitical Risks**: The geopolitical climate can impact the global supply chain and IT infrastructure investments, potentially affecting SK Telecomâ€™s operations if there are changes in trade policies or regional stability.\n",
      "\n",
      "By focusing on AI data centers, SK Telecom is well-positioned to capitalize on these economic trends, though careful management of associated risks is necessary to ensure sustainable growth. This economic analysis provides a basis for assessing the broader impacts of SK Telecom's AI data center initiatives.\n",
      "---------- WhiteCollarWorker ----------\n",
      "[FunctionCall(id='call_ZtVtpVxTKjEH4lcRMvGAdp40', arguments='{\"query\":\"SK Telecom AI data centers 2023 strategies investments expansion\"}', name='web_search_tool')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyungilkim/Documents/Labs/demo/multi-agent-workshop/.venv/lib/python3.13/site-packages/autogen_agentchat/agents/_assistant_agent.py:416: UserWarning: Both tool_calls and content are present in the message. This is unexpected. content will be ignored, tool_calls will be used.\n",
      "  model_result = await self._model_client.create(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- WhiteCollarWorker ----------\n",
      "[FunctionExecutionResult(content='[{\\'title\\': \\'SK Telecom Announces AI Pyramid Strategy to ... - SK telecom newsroom\\', \\'href\\': \\'https://news.sktelecom.com/en/678\\', \\'body\\': \\'â€¢ By 2028, SKT will triple the proportion of its AI-related investments and become a global AI company with revenue of KRW 25 trillion. SK Telecom (NYSE:SKM, \"SKT\") today announced its ambition to become a global AI company by strengthening its own AI competitiveness and cooperating with partners throughout the globe.\\'}]', call_id='call_ZtVtpVxTKjEH4lcRMvGAdp40', is_error=False)]\n",
      "---------- WhiteCollarWorker ----------\n",
      "### SK Telecom's Strategies and Investments in AI Data Centers\n",
      "\n",
      "1. **AI Pyramid Strategy**:\n",
      "   - SK Telecom is committed to becoming a leading global AI company by focusing on its \"AI Pyramid Strategy.\" This involves significantly increasing its AI-related investments with an aim to triple them by 2028. This approach is designed not only to boost its in-house AI capabilities but also to enhance collaboration with partners worldwide, thus strengthening its competitive edge in the global market.\n",
      "\n",
      "2. **Business Expansion and Revenue Goals**:\n",
      "   - By implementing this strategy, SK Telecom plans to achieve a revenue of KRW 25 trillion, underscoring its emphasis on AI as a major growth driver. The expansion of AI data centers is a core component of this strategy, leveraging advances in digital infrastructure to facilitate service delivery across different sectors.\n",
      "\n",
      "3. **Partnerships and Integration**:\n",
      "   - SK Telecom recognizes the importance of partnerships in extending its AI capabilities and data center footprint. By integrating AI centers with its existing telecom infrastructure, SK Telecom is poised to offer enhanced services that combine telecommunications and AI solutions, ensuring seamless and innovative customer experiences.\n",
      "\n",
      "4. **Focus Areas for AI Development**:\n",
      "   - The company's AI strategy includes not only the enhancement of its data centers but also innovations in AI service offerings such as AI-based customer interaction platforms, smart environments, and efficient data management systems. This holistic approach is aimed at creating an ecosystem where AI solutions drive business value and customer satisfaction.\n",
      "\n",
      "In summary, SK Telecom's strategic focus on AI data centers is an integral part of its ambition to assert itself as a global AI leader. The company's efforts in expanding these capabilities are expected to significantly impact its business model and revenue streams positively.\n",
      "---------- Environmentalist ----------\n",
      "### Environmental Impact of AI Data Centers\n",
      "\n",
      "1. **Energy Consumption and Carbon Footprint**:\n",
      "   - AI data centers are high energy consumers due to the extensive computational power they require. This has direct implications for SK Telecom's carbon footprint, as increased energy use typically correlates with higher carbon emissions. However, measures can be taken to mitigate this impact through innovative cooling solutions, energy-efficient hardware, and adoption of renewable energy sources.\n",
      "\n",
      "2. **Sustainable Practices**:\n",
      "   - To address energy consumption concerns, SK Telecom could implement various sustainable practices in the operation of its AI data centers. This includes optimizing data center design for energy efficiency, utilizing AI for smarter energy management solutions, and investing in green energy technologies to power its facilities.\n",
      "\n",
      "3. **Renewable Energy Initiatives**:\n",
      "   - Integrating renewable energy sources, such as wind or solar power, into the energy supply for data centers can significantly reduce environmental impact. SK Telecomâ€™s commitment to sustainability will be pivotal in reducing dependency on fossil fuels and minimizing greenhouse gas emissions.\n",
      "\n",
      "4. **Positive Contributions to Environmental Sustainability**:\n",
      "   - By focusing on building AI data centers that prioritize sustainability, SK Telecom has the opportunity to lead by example, promoting green tech innovations and contributing to a circular economy. This can include participating in partnerships to develop green technologies and leveraging AI for environmental monitoring and improvement projects.\n",
      "\n",
      "5. **Waste Management and Resource Efficiency**:\n",
      "   - Implementing efficient waste management systems and recycling e-waste generated from data center operations is crucial. Efforts should be made to utilize materials and electronics that are sustainable and environmentally friendly, thus reducing the overall environmental footprint.\n",
      "\n",
      "In conclusion, SK Telecom's focus on AI data centers presents both challenges and opportunities from an environmental perspective. Emphasizing sustainability in these operations can result in significant contributions to reducing environmental impacts while positioning SK Telecom as a responsible leader in AI and digital transformations.\n",
      "---------- ReportAgent ----------\n",
      "[FunctionCall(id='call_fLWC9g9lwARF4HkKQ2jg0qX8', arguments='{\"report\":\"### Global Business Impact Analysis of AI Data Centers that SK Telecom is Focusing on Recently\\\\n\\\\n#### Economic Impact Analysis\\\\n\\\\n1. **Market Trends and Growth Opportunities**:\\\\n    - The proliferation of AI is inducing a significant surge in global data center demand, projected to increase power demand by 50% by 2027 and up to 165% by 2030. This showcases a massive growth potential for SK Telecom in the AI data center sector.\\\\n    \\\\n2. **Economic Benefits**:\\\\n    - **Job Creation**: Expansion of AI data centers by SK Telecom will bolster job creation across technology and construction sectors.\\\\n    - **Innovation and Competitiveness**: Advanced AI data centers can position SK Telecom as a leader in digital services, enhancing its global competitiveness.\\\\n    - **Investment and Revenue Generation**: Investments in AI are expected to attract additional investments and increased revenue streams, directly and indirectly nurturing the AI ecosystem.\\\\n\\\\n3. **Potential Risks**:\\\\n    - **Energy Consumption**: Increased AI capabilities necessitate higher energy use, demanding a balance with sustainable practices.\\\\n    - **Geopolitical Risks**: Global supply chain disruptions or changes in trade policies could impact operations.\\\\n\\\\nSK Telecom\\'s engagement in AI data centers positions it to capitalize on economic trends, with careful management of risks required for sustainable growth.\\\\n\\\\n#### SK Telecom\\'s Strategic Engagement\\\\n\\\\n1. **AI Pyramid Strategy**:\\\\n   - Intensifying AI-related investments aimed at tripling by 2028 to boost in-house AI and forge global partnerships.\\\\n\\\\n2. **Business Expansion**:\\\\n   - Plans to achieve a revenue of KRW 25 trillion highlight AI as a major growth driver, focusing on digital infrastructure advances.\\\\n\\\\n3. **Partnerships and Integration**:\\\\n   - Strategic alliances extend AI and data center capabilities, integrating with telecom infrastructure for enhanced services.\\\\n\\\\n4. **AI Development Focus**:\\\\n   - Innovation in AI service offerings, such as smart environments and data management, aims to create a value-driven AI ecosystem.\\\\n\\\\nSK Telecom\\'s strategic emphasis on AI data centers aligns with its vision of becoming a global AI leader, impacting its business model positively.\\\\n\\\\n#### Environmental Impact Analysis\\\\n\\\\n1. **Energy Consumption Challenges**:\\\\n   - AI data centers are energy-intensive, affecting SK Telecom\\'s carbon emissions. Mitigation involves energy-efficient hardware and renewable energy adoption.\\\\n\\\\n2. **Sustainable Practices**:\\\\n   - Implementing data center design optimizations, smart energy management, and investing in green tech can reduce environmental impact.\\\\n\\\\n3. **Renewable Energy Initiatives**:\\\\n   - Leveraging renewable energy sources can significantly curtail environmental footprints.\\\\n\\\\n4. **Positive Environmental Contributions**:\\\\n   - By prioritizing sustainability in AI data centers, SK Telecom can lead innovations in green tech, advancing a circular economy.\\\\n\\\\n5. **Resource Efficiency**:\\\\n   - Efficient waste management and use of sustainable materials reduce the overall environmental impact.\\\\n\\\\nSK Telecom\\'s focus on sustainable AI data center operations promotes both environmental responsibility and leadership in eco-friendly AI advancements.\\\\n\\\\n### Conclusion\\\\nSK Telecom\\'s strategic focus on AI data centers marks a significant advancement in the global AI landscape. Economic, strategic, and environmental analyses reveal that SK Telecom is positioned to capitalize on technological advancements while committing to sustainability. Leveraging its AI Pyramid Strategy and partnerships, the company is expected to drive innovation and market leadership within the digital transformation era, all while adhering to environmental stewardship. The alignment of economic goals with strategic initiatives and sustainability practices underscores SK Telecom\\'s comprehensive approach to evolving its business amidst ongoing technological developments.\"}', name='save_report_tool')]\n",
      "---------- ReportAgent ----------\n",
      "[FunctionExecutionResult(content='Report saved successfully.', call_id='call_fLWC9g9lwARF4HkKQ2jg0qX8', is_error=False)]\n",
      "---------- ReportAgent ----------\n",
      "The report on \"Global Business Impact Analysis of AI Data Centers that SK Telecom is Focusing on Recently\" has been successfully compiled and saved. Please let me know if there is anything else you need.\n",
      "---------- Economist ----------\n",
      "The report on the \"Global Business Impact Analysis of AI Data Centers that SK Telecom is Focusing on Recently\" has been completed. Here's a brief summary:\n",
      "\n",
      "1. **Economic Impact**:\n",
      "   - AI data centers are a burgeoning market opportunity, with significant global growth expected in energy demand and infrastructure. SK Telecom, by focusing on this sector, is likely to benefit economically through job creation, enhanced competitiveness, and new revenue streams. However, energy consumption and geopolitical risks must be managed.\n",
      "\n",
      "2. **Strategic Initiatives**:\n",
      "   - SK Telecom is implementing its \"AI Pyramid Strategy\" to become a global AI leader, planning to increase AI investments and collaborate internationally. The integration of AI data centers with its existing telecom infrastructure is central to this strategy, aiming for substantial revenue growth and innovative service delivery.\n",
      "\n",
      "3. **Environmental Considerations**:\n",
      "   - The energy-intensive nature of AI data centers requires sustainable practices to minimize their carbon footprint. SK Telecom can leverage renewable energy and efficient design to mitigate environmental impact. This approach not only reduces emissions but also enhances SK Telecom's reputation as a sustainable and responsible corporation.\n",
      "\n",
      "Each section provides detailed insights and analyses to underscore the potential global business impact of SK Telecom's investment in AI data centers.\n",
      "\n",
      "If there's anything more you need or further details are required, feel free to ask!\n",
      "---------- ReportAgent ----------\n",
      "The \"Global Business Impact Analysis of AI Data Centers that SK Telecom is Focusing on Recently\" report has been successfully completed and is well-summarized. Here's a concise outline of the report:\n",
      "\n",
      "1. **Economic Impact**:\n",
      "   - **Growth Opportunities**: AI data centers are a significant market opportunity with expected global growth. SK Telecom's focus could lead to job creation, improved competitiveness, and increased revenue, while managing energy consumption and geopolitical risks.\n",
      "\n",
      "2. **Strategic Initiatives**:\n",
      "   - **AI Pyramid Strategy**: SK Telecom aims to become a global AI leader through increased AI investments and international collaborations. Integrating AI data centers into its infrastructure is pivotal for substantial growth and innovative service offerings.\n",
      "\n",
      "3. **Environmental Considerations**:\n",
      "   - **Sustainability**: Mitigating the energy consumption of AI data centers is key. SK Telecom can use renewable energy and efficient design to reduce its environmental footprint, enhancing its reputation as a sustainable company.\n",
      "\n",
      "These sections collectively provide a comprehensive analysis of the business and environmental impact of SK Telecom's AI data center focus. If any further elaboration or additional information is needed, please feel free to request.\n",
      "---------- ReportAgent ----------\n",
      "If you need more detailed insights or further assistance, please let me know!\n",
      "---------- PlanningAgent ----------\n",
      "The report on the \"Global Business Impact Analysis of AI Data Centers that SK Telecom is Focusing on Recently\" is complete. In summary:\n",
      "\n",
      "1. **Economic Impact**: AI data centers present a growing market opportunity, promising economic benefits like job creation and increased competitiveness for SK Telecom. However, energy consumption and geopolitical risks must be monitored.\n",
      "\n",
      "2. **Strategic Initiatives**: SK Telecom's \"AI Pyramid Strategy\" aims for global AI leadership through increased investments and international collaborations, with AI data centers playing a critical role in business growth and service innovation.\n",
      "\n",
      "3. **Environmental Considerations**: To address the environmental impact, sustainable practices such as renewable energy adoption and efficient design are vital. These practices not only reduce carbon footprints but also bolster SK Telecom's image as an environmentally responsible leader.\n",
      "\n",
      "This holistic analysis highlights both the opportunities and challenges associated with SK Telecom's focus on AI data centers, providing a foundation for strategic decision-making. TERMINATE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='ìµœê·¼ SKí…”ë ˆì½¤ì´ ì§‘ì¤‘í•˜ê³  ìˆëŠ” AI ë°ì´í„°ì„¼í„°ì˜ ê¸€ë¡œë²Œ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥ ë¶„ì„â€ì— ëŒ€í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.', type='TextMessage'), TextMessage(source='PlanningAgent', models_usage=RequestUsage(prompt_tokens=141, completion_tokens=197), content='To create a comprehensive report on the \"Global Business Impact Analysis of AI Data Centers that SK Telecom is Focusing on Recently,\" we need to break down the task into several subtasks, engaging the appropriate team members to address different aspects of the report.\\n\\n1. Economist: Analyze the economic implications of AI data centers on a global scale, including market trends, potential growth opportunities, and economic benefits for SK Telecom.\\n2. WhiteCollarWorker: Research SK Telecom\\'s strategies and investments in AI data centers, including partnerships, expansion plans, and integration into their existing business model.\\n3. Environmentalist: Examine the environmental impact of AI data centers, highlighting both the challenges and the positive contributions that SK Telecom might be making with sustainable practices.\\n4. ReportAgent: Compile the information and analysis provided by the Economist, WhiteCollarWorker, and Environmentalist into a cohesive report, ensuring all sections are clearly presented and conclusions are well-supported.\\n\\nPlease proceed with each task and provide your findings.', type='TextMessage'), ToolCallRequestEvent(source='Economist', models_usage=RequestUsage(prompt_tokens=319, completion_tokens=21), content=[FunctionCall(id='call_6PGN1VPNbJfLExFz46XCvWj5', arguments='{\"query\":\"global economic impact of AI data centers\"}', name='web_search_tool')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='Economist', models_usage=None, content=[FunctionExecutionResult(content=\"[{'title': 'AI to drive 165% increase in data center power demand by 2030', 'href': 'https://www.goldmansachs.com/insights/articles/ai-to-drive-165-increase-in-data-center-power-demand-by-2030', 'body': 'The explosion in interest in generative artificial intelligence has resulted in an arms race to develop the technology, which will require many high-density data centers as well as much more electricity to power them.. Goldman Sachs Research forecasts global power demand from data centers will increase 50% by 2027 and by as much as 165% by the end of the decade (compared with 2023), writes ...'}]\", call_id='call_6PGN1VPNbJfLExFz46XCvWj5', is_error=False)], type='ToolCallExecutionEvent'), TextMessage(source='Economist', models_usage=RequestUsage(prompt_tokens=450, completion_tokens=365), content=\"### Global Economic Impact Analysis of AI Data Centers\\n\\n1. **Market Trends and Growth Opportunities**:\\n    - The rise of artificial intelligence (AI) is driving a significant increase in the demand for data centers globally. This trend is expected to continue, with power demand from data centers anticipated to increase by 50% by 2027 and up to 165% by 2030. This reflects a substantial growth opportunity for companies like SK Telecom involved in the AI data center segment.\\n    \\n2. **Economic Benefits**:\\n    - **Job Creation**: As SK Telecom expands its AI data centers, it will likely contribute to job creation in both the technology and construction sectors, as well as ongoing operational roles.\\n    - **Innovation and Competitiveness**: The presence of advanced AI data centers will position SK Telecom as a leader in digital services and technologies, enhancing its competitiveness in the global market.\\n    - **Investment and Revenue Generation**: Investments in AI infrastructure are likely to attract further domestic and international investments, leading to an increase in revenue streams both directly (through data services) and indirectly (by supporting the AI ecosystem development).\\n\\n3. **Potential Risks and Considerations**:\\n    - **Energy Consumption**: As the demand for AI capabilities grows, so does the energy required to power these data centers. Companies must balance growth with sustainable practices.\\n    - **Geopolitical Risks**: The geopolitical climate can impact the global supply chain and IT infrastructure investments, potentially affecting SK Telecomâ€™s operations if there are changes in trade policies or regional stability.\\n\\nBy focusing on AI data centers, SK Telecom is well-positioned to capitalize on these economic trends, though careful management of associated risks is necessary to ensure sustainable growth. This economic analysis provides a basis for assessing the broader impacts of SK Telecom's AI data center initiatives.\", type='TextMessage'), ToolCallRequestEvent(source='WhiteCollarWorker', models_usage=RequestUsage(prompt_tokens=691, completion_tokens=77), content=[FunctionCall(id='call_ZtVtpVxTKjEH4lcRMvGAdp40', arguments='{\"query\":\"SK Telecom AI data centers 2023 strategies investments expansion\"}', name='web_search_tool')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='WhiteCollarWorker', models_usage=None, content=[FunctionExecutionResult(content='[{\\'title\\': \\'SK Telecom Announces AI Pyramid Strategy to ... - SK telecom newsroom\\', \\'href\\': \\'https://news.sktelecom.com/en/678\\', \\'body\\': \\'â€¢ By 2028, SKT will triple the proportion of its AI-related investments and become a global AI company with revenue of KRW 25 trillion. SK Telecom (NYSE:SKM, \"SKT\") today announced its ambition to become a global AI company by strengthening its own AI competitiveness and cooperating with partners throughout the globe.\\'}]', call_id='call_ZtVtpVxTKjEH4lcRMvGAdp40', is_error=False)], type='ToolCallExecutionEvent'), TextMessage(source='WhiteCollarWorker', models_usage=RequestUsage(prompt_tokens=793, completion_tokens=341), content='### SK Telecom\\'s Strategies and Investments in AI Data Centers\\n\\n1. **AI Pyramid Strategy**:\\n   - SK Telecom is committed to becoming a leading global AI company by focusing on its \"AI Pyramid Strategy.\" This involves significantly increasing its AI-related investments with an aim to triple them by 2028. This approach is designed not only to boost its in-house AI capabilities but also to enhance collaboration with partners worldwide, thus strengthening its competitive edge in the global market.\\n\\n2. **Business Expansion and Revenue Goals**:\\n   - By implementing this strategy, SK Telecom plans to achieve a revenue of KRW 25 trillion, underscoring its emphasis on AI as a major growth driver. The expansion of AI data centers is a core component of this strategy, leveraging advances in digital infrastructure to facilitate service delivery across different sectors.\\n\\n3. **Partnerships and Integration**:\\n   - SK Telecom recognizes the importance of partnerships in extending its AI capabilities and data center footprint. By integrating AI centers with its existing telecom infrastructure, SK Telecom is poised to offer enhanced services that combine telecommunications and AI solutions, ensuring seamless and innovative customer experiences.\\n\\n4. **Focus Areas for AI Development**:\\n   - The company\\'s AI strategy includes not only the enhancement of its data centers but also innovations in AI service offerings such as AI-based customer interaction platforms, smart environments, and efficient data management systems. This holistic approach is aimed at creating an ecosystem where AI solutions drive business value and customer satisfaction.\\n\\nIn summary, SK Telecom\\'s strategic focus on AI data centers is an integral part of its ambition to assert itself as a global AI leader. The company\\'s efforts in expanding these capabilities are expected to significantly impact its business model and revenue streams positively.', type='TextMessage'), TextMessage(source='Environmentalist', models_usage=RequestUsage(prompt_tokens=1041, completion_tokens=377), content=\"### Environmental Impact of AI Data Centers\\n\\n1. **Energy Consumption and Carbon Footprint**:\\n   - AI data centers are high energy consumers due to the extensive computational power they require. This has direct implications for SK Telecom's carbon footprint, as increased energy use typically correlates with higher carbon emissions. However, measures can be taken to mitigate this impact through innovative cooling solutions, energy-efficient hardware, and adoption of renewable energy sources.\\n\\n2. **Sustainable Practices**:\\n   - To address energy consumption concerns, SK Telecom could implement various sustainable practices in the operation of its AI data centers. This includes optimizing data center design for energy efficiency, utilizing AI for smarter energy management solutions, and investing in green energy technologies to power its facilities.\\n\\n3. **Renewable Energy Initiatives**:\\n   - Integrating renewable energy sources, such as wind or solar power, into the energy supply for data centers can significantly reduce environmental impact. SK Telecomâ€™s commitment to sustainability will be pivotal in reducing dependency on fossil fuels and minimizing greenhouse gas emissions.\\n\\n4. **Positive Contributions to Environmental Sustainability**:\\n   - By focusing on building AI data centers that prioritize sustainability, SK Telecom has the opportunity to lead by example, promoting green tech innovations and contributing to a circular economy. This can include participating in partnerships to develop green technologies and leveraging AI for environmental monitoring and improvement projects.\\n\\n5. **Waste Management and Resource Efficiency**:\\n   - Implementing efficient waste management systems and recycling e-waste generated from data center operations is crucial. Efforts should be made to utilize materials and electronics that are sustainable and environmentally friendly, thus reducing the overall environmental footprint.\\n\\nIn conclusion, SK Telecom's focus on AI data centers presents both challenges and opportunities from an environmental perspective. Emphasizing sustainability in these operations can result in significant contributions to reducing environmental impacts while positioning SK Telecom as a responsible leader in AI and digital transformations.\", type='TextMessage'), ToolCallRequestEvent(source='ReportAgent', models_usage=RequestUsage(prompt_tokens=1426, completion_tokens=765), content=[FunctionCall(id='call_fLWC9g9lwARF4HkKQ2jg0qX8', arguments='{\"report\":\"### Global Business Impact Analysis of AI Data Centers that SK Telecom is Focusing on Recently\\\\n\\\\n#### Economic Impact Analysis\\\\n\\\\n1. **Market Trends and Growth Opportunities**:\\\\n    - The proliferation of AI is inducing a significant surge in global data center demand, projected to increase power demand by 50% by 2027 and up to 165% by 2030. This showcases a massive growth potential for SK Telecom in the AI data center sector.\\\\n    \\\\n2. **Economic Benefits**:\\\\n    - **Job Creation**: Expansion of AI data centers by SK Telecom will bolster job creation across technology and construction sectors.\\\\n    - **Innovation and Competitiveness**: Advanced AI data centers can position SK Telecom as a leader in digital services, enhancing its global competitiveness.\\\\n    - **Investment and Revenue Generation**: Investments in AI are expected to attract additional investments and increased revenue streams, directly and indirectly nurturing the AI ecosystem.\\\\n\\\\n3. **Potential Risks**:\\\\n    - **Energy Consumption**: Increased AI capabilities necessitate higher energy use, demanding a balance with sustainable practices.\\\\n    - **Geopolitical Risks**: Global supply chain disruptions or changes in trade policies could impact operations.\\\\n\\\\nSK Telecom\\'s engagement in AI data centers positions it to capitalize on economic trends, with careful management of risks required for sustainable growth.\\\\n\\\\n#### SK Telecom\\'s Strategic Engagement\\\\n\\\\n1. **AI Pyramid Strategy**:\\\\n   - Intensifying AI-related investments aimed at tripling by 2028 to boost in-house AI and forge global partnerships.\\\\n\\\\n2. **Business Expansion**:\\\\n   - Plans to achieve a revenue of KRW 25 trillion highlight AI as a major growth driver, focusing on digital infrastructure advances.\\\\n\\\\n3. **Partnerships and Integration**:\\\\n   - Strategic alliances extend AI and data center capabilities, integrating with telecom infrastructure for enhanced services.\\\\n\\\\n4. **AI Development Focus**:\\\\n   - Innovation in AI service offerings, such as smart environments and data management, aims to create a value-driven AI ecosystem.\\\\n\\\\nSK Telecom\\'s strategic emphasis on AI data centers aligns with its vision of becoming a global AI leader, impacting its business model positively.\\\\n\\\\n#### Environmental Impact Analysis\\\\n\\\\n1. **Energy Consumption Challenges**:\\\\n   - AI data centers are energy-intensive, affecting SK Telecom\\'s carbon emissions. Mitigation involves energy-efficient hardware and renewable energy adoption.\\\\n\\\\n2. **Sustainable Practices**:\\\\n   - Implementing data center design optimizations, smart energy management, and investing in green tech can reduce environmental impact.\\\\n\\\\n3. **Renewable Energy Initiatives**:\\\\n   - Leveraging renewable energy sources can significantly curtail environmental footprints.\\\\n\\\\n4. **Positive Environmental Contributions**:\\\\n   - By prioritizing sustainability in AI data centers, SK Telecom can lead innovations in green tech, advancing a circular economy.\\\\n\\\\n5. **Resource Efficiency**:\\\\n   - Efficient waste management and use of sustainable materials reduce the overall environmental impact.\\\\n\\\\nSK Telecom\\'s focus on sustainable AI data center operations promotes both environmental responsibility and leadership in eco-friendly AI advancements.\\\\n\\\\n### Conclusion\\\\nSK Telecom\\'s strategic focus on AI data centers marks a significant advancement in the global AI landscape. Economic, strategic, and environmental analyses reveal that SK Telecom is positioned to capitalize on technological advancements while committing to sustainability. Leveraging its AI Pyramid Strategy and partnerships, the company is expected to drive innovation and market leadership within the digital transformation era, all while adhering to environmental stewardship. The alignment of economic goals with strategic initiatives and sustainability practices underscores SK Telecom\\'s comprehensive approach to evolving its business amidst ongoing technological developments.\"}', name='save_report_tool')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='ReportAgent', models_usage=None, content=[FunctionExecutionResult(content='Report saved successfully.', call_id='call_fLWC9g9lwARF4HkKQ2jg0qX8', is_error=False)], type='ToolCallExecutionEvent'), TextMessage(source='ReportAgent', models_usage=RequestUsage(prompt_tokens=2171, completion_tokens=40), content='The report on \"Global Business Impact Analysis of AI Data Centers that SK Telecom is Focusing on Recently\" has been successfully compiled and saved. Please let me know if there is anything else you need.', type='TextMessage'), TextMessage(source='Economist', models_usage=RequestUsage(prompt_tokens=1646, completion_tokens=264), content='The report on the \"Global Business Impact Analysis of AI Data Centers that SK Telecom is Focusing on Recently\" has been completed. Here\\'s a brief summary:\\n\\n1. **Economic Impact**:\\n   - AI data centers are a burgeoning market opportunity, with significant global growth expected in energy demand and infrastructure. SK Telecom, by focusing on this sector, is likely to benefit economically through job creation, enhanced competitiveness, and new revenue streams. However, energy consumption and geopolitical risks must be managed.\\n\\n2. **Strategic Initiatives**:\\n   - SK Telecom is implementing its \"AI Pyramid Strategy\" to become a global AI leader, planning to increase AI investments and collaborate internationally. The integration of AI data centers with its existing telecom infrastructure is central to this strategy, aiming for substantial revenue growth and innovative service delivery.\\n\\n3. **Environmental Considerations**:\\n   - The energy-intensive nature of AI data centers requires sustainable practices to minimize their carbon footprint. SK Telecom can leverage renewable energy and efficient design to mitigate environmental impact. This approach not only reduces emissions but also enhances SK Telecom\\'s reputation as a sustainable and responsible corporation.\\n\\nEach section provides detailed insights and analyses to underscore the potential global business impact of SK Telecom\\'s investment in AI data centers.\\n\\nIf there\\'s anything more you need or further details are required, feel free to ask!', type='TextMessage'), TextMessage(source='ReportAgent', models_usage=RequestUsage(prompt_tokens=2524, completion_tokens=235), content='The \"Global Business Impact Analysis of AI Data Centers that SK Telecom is Focusing on Recently\" report has been successfully completed and is well-summarized. Here\\'s a concise outline of the report:\\n\\n1. **Economic Impact**:\\n   - **Growth Opportunities**: AI data centers are a significant market opportunity with expected global growth. SK Telecom\\'s focus could lead to job creation, improved competitiveness, and increased revenue, while managing energy consumption and geopolitical risks.\\n\\n2. **Strategic Initiatives**:\\n   - **AI Pyramid Strategy**: SK Telecom aims to become a global AI leader through increased AI investments and international collaborations. Integrating AI data centers into its infrastructure is pivotal for substantial growth and innovative service offerings.\\n\\n3. **Environmental Considerations**:\\n   - **Sustainability**: Mitigating the energy consumption of AI data centers is key. SK Telecom can use renewable energy and efficient design to reduce its environmental footprint, enhancing its reputation as a sustainable company.\\n\\nThese sections collectively provide a comprehensive analysis of the business and environmental impact of SK Telecom\\'s AI data center focus. If any further elaboration or additional information is needed, please feel free to request.', type='TextMessage'), TextMessage(source='ReportAgent', models_usage=RequestUsage(prompt_tokens=2765, completion_tokens=16), content='If you need more detailed insights or further assistance, please let me know!', type='TextMessage'), TextMessage(source='PlanningAgent', models_usage=RequestUsage(prompt_tokens=2030, completion_tokens=189), content='The report on the \"Global Business Impact Analysis of AI Data Centers that SK Telecom is Focusing on Recently\" is complete. In summary:\\n\\n1. **Economic Impact**: AI data centers present a growing market opportunity, promising economic benefits like job creation and increased competitiveness for SK Telecom. However, energy consumption and geopolitical risks must be monitored.\\n\\n2. **Strategic Initiatives**: SK Telecom\\'s \"AI Pyramid Strategy\" aims for global AI leadership through increased investments and international collaborations, with AI data centers playing a critical role in business growth and service innovation.\\n\\n3. **Environmental Considerations**: To address the environmental impact, sustainable practices such as renewable energy adoption and efficient design are vital. These practices not only reduce carbon footprints but also bolster SK Telecom\\'s image as an environmentally responsible leader.\\n\\nThis holistic analysis highlights both the opportunities and challenges associated with SK Telecom\\'s focus on AI data centers, providing a foundation for strategic decision-making. TERMINATE', type='TextMessage')], stop_reason=\"Text 'TERMINATE' mentioned, Maximum number of messages 10 reached, current message count: 10\")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(team.run_stream(task=\"ìµœê·¼ SKí…”ë ˆì½¤ì´ ì§‘ì¤‘í•˜ê³  ìˆëŠ” AI ë°ì´í„°ì„¼í„°ì˜ ê¸€ë¡œë²Œ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥ ë¶„ì„â€ì— ëŒ€í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to https://microsoft.github.io/autogen/docs/ for information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
